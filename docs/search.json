{
  "articles": [
    {
      "path": "08-ddm.html",
      "title": "Cognitive Process Models",
      "description": "Teil 8: Diffusion Decision Model of Decision Making\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "2021-05-25",
      "contents": "\n\nContents\nEntscheidungen\nDiffusion Decision Model\nModel in R\nDrift rate\nBias\nBoundary separation\nNon-decision time\n\nSimulationen\nModel-based Cognitive Neuroscience\nBeispiele\nBias in the Brain\n\nDDM mit brms\nResultat\n\n\n\n\nlibrary(tidyverse)\nlibrary(viridis)\n\ntheme_set(theme_grey(base_size = 14) +\n            theme(panel.grid = element_blank()))\n\n\n\nEntscheidungen\nIn der letzten Sitzung haben wir Daten aus einem Lexical Decision Task angeschaut, bei dem Versuchspersonen einen Stimulus in eine von zwei Antwortkategorien einteilen mussten. Dabei haben wir die Reaktionszeiten von korrekten Antworten angeschaut. Diese Art von Experimenten wird sehr häufig verwendet, und wird oft choice response time Task genannt.\nWenn wir aber nur die korrekten Antworten betrachten, ignorieren wir sehr viel Information, die verwendet werden könnte, um etwas über die kognitiven Prozesse ausssagen zu können, welche dieser Art von Entscheidung zugrunde liegen könnten. Zum Beispiel wissen wir, dass die Fehler, welche Menschen in einer Speed-Stress Bedingung machen, schneller als korrekte Antworten sind, während in einer Accuracy-Stress Bedingung Fehler eher langsamer als korrekte Antworten sind. Solche Befunde sind schwierig zu erklären, ohne dass man dafür mathematische Modelle macht.\nAus diesem Grund hat Roger Ratcliff Ende der 70er Jahre das Diffusion Decision Modell (DDM=) entwickelt, welches eine Entscheidung zwischen zwei Alternativen in mehrere kognitive Komponenten zerlegt, und sowohl die Antworten als auch die Reaktionszeiten erklären kann (Ratcliff and McKoon 2008). Auf seiner Website führt Ratcliff ine Liste von Anwendungen des DDM, z.B. für ADHS, Altern, Depression, etc.\nDiffusion Decision Model\nDas von Ratcliff entwickelte Modell hat seinen Ursprung in Modellen zu den Bewegungen von Partikeln in einer Flüssigkeit, und geht auf Arbeiten von Albert Einstein und Norbert Wiener zurück.\n\nHier schauen wir uns eine vereinfachte Version dieses Modells an, welches nur 4 Parameter—im “standard” DDM hat es 7 Parameter.\nDie Grundidee ist, dass wir Evidenz für die eine oder die andere Antwortalternative brauchen, um eine Entscheidung zu treffen, und dass diese Evidenz über die Zeit akkumuliert wird. Diese Evidenz wird, je nach Task, von einem Teil unseres Gehirns verarbeitet, so dass sie für die Entscheidung zur Verfügung steht. Wenn wir beispielsweise eine perzeptuelle Entscheidung modellieren, wie etwa die Entscheidung, ob sich etwas nach rechts oder links bewegt, nehmen wir an, dass die Evidenz von den kortikalen Arealen verarbeitet wird, welche für Bewegungswahrnehmung zuständig sind. Diese Evidenz wird dann kontinuerlich einem Decision Process verfügbar gemacht, und zwar in Form einer Verteilung.\nWir nehmen nun an, dass wir die Zeit in diskrete kleine Intervalle \\(\\Delta t\\) einteilen können. Pro Zeiteinheit wird eine Zufallszahl aus dieser Evidenzverteilung gezogen wird, so dass positive Werte als Evidenz für die eine Antwortalternative gezählt wird, während negative Werte als Evidenz für die andere Antwortalternative gezählt wird. Diese Evidenz wird über die Zeit aufsummiert, bis entweder eine obere oder eine untere Grenze erreicht wird. Die aufsummierte Evidenz wird Decision Variable genannt. Ist eine der Grenzen erreicht, wird eine Antwort ausgelöst. Die Tendenz der Decision Variable, auf- oder abzusteigen, nennt man drift rate. Diese hat natürlich etwas mit dem Stimulus zu tun—je stärker der Stimulus, desto grösser wird die drift rate.\nIn Experimenten zum Bewegungssehen wird oft ein ‘random dot motion’ task verwendet. Hier muss entschieden werden, ob sich eine Punktwolke nach rechts oder nach links bewegt. Es wird hier angenommen, dass die drift rate von der Stimulusstärke abhängt; in diesem Fall ist das die Kohärenz, d.h. der Anteil der Punkte, welcher sich kohärent in eine Richtung bewegt.\n\n\n\nFigure 1: Figure from Mulder et al. (2012)\n\n\n\nDie Distanz zwischen den Grenzen wird threshold gennant, und der Anfangspunkt der Evidenzakkumulierung wird bias genannt. Die letzte wichtige Komponente dieses Modells ist die non-decision time. Darunter werden alle Prozesse zusammengefasst, welche ausgefährt werden müssen, jedoch nicht direkt mit der Entscheidung zu tun haben. Darunter fällt z.B. die Ausführung der Antwort durch das motorische System, aber auch die sensorische Verarbeitung. Wird dieser Entscheidungsprozess oft wiederholt, resultieren daraus Reaktionszeitverteilungen für korrekte und inkorrekte Entscheidungen.\n\n\n\nFigure 2: Figure from Vinding et al. (2018)\n\n\n\nModel in R\nIn R können wir die aktuelle Decision Variable zu Zeitpunkt \\(t\\) als normalverteilte Zufallszahl modellieren, bei der die driftrate den Mittelwert der Evidenz repräsentiert, und sd die Standardabweichung.\n\n\ndriftrate <- 0.5\nsd <- 0.1\nevidence <- rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n\n[1] 0.4381618\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungefähr 0.44 beträgt. Da die Evidenz die durchschnittliche Steigung repräsentiert, wird Evidenz \\(>0\\) dazu führen, dass an Schritt in Richtung der oberen Grenze gemaacht wird. Wäre die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also möglich, dass die Evidenz zufällig negativ wird, obwohl die drift rate, d.h. die Repräsentation ser Stimulusstärke, positiv ist.\n\nEs wird angenommen, dass dieser Aspekt einigermassen gut die Vorgänge im Gehirn abbildet, da die neuronalen Antworten auf einen Reiz variabel sind (dies bedeutet, dass Neurone immer unterschiedlich auf einen Reiz reagieren, auch wenn dieser gleich bleibt).\nWenn wir dieses Prozess nun über einen Zeitraum wiederholen, und die evidence Werte aufsummieren, erhalten wir die decision variable. Diese sieht aus wie ein random walk mit einem Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk simulieren\nEin random walk ist das Resultat der Aufsummierung von Zufallszahlen. Probieren Sie es selber aus; simulieren Sie einen random walk mit 100 Zeitschritten. Fangen Sie bei \\(0\\) an, ziehen Sie 99 normalverteilte Zufallszahlen und berechnen Sie die kumulierte Summe. Plotten Sie das Resultat.\nDieser random walk hat keinen Trend, weil wir immer aus einer Normalverteilung mit Mittelwert \\(\\mu=0\\) ziehen. Wenn wir stattdessen aus einer Verteilung mit \\(\\mu=0.1\\) ziehen, erhalten wir einen positiven Trend.\n\n\nShow code\n\nset.seed(546)\n\n# hier z.B> standardnormalverteilte Zahlen\nzufallszahlen_1 <- c(0, rnorm(99, 0, 1))\nrandom_walk_1 <- cumsum(zufallszahlen_1)\nplot(1:100, random_walk_1, type = \"s\", col = \"#7fc97f\", \n     ylim=c(-10,30), lwd = 2)\n\nzufallszahlen_2 <- c(0, rnorm(99, 0.3, 1))\nrandom_walk_2 <- cumsum(zufallszahlen_2)\n\nlines(1:100, random_walk_2, pch = 18, col = \"#beaed4\", \n      type = \"s\", lwd = 2)\n\nlegend(\"topleft\", legend=c(\"Ohne Trend\", \"Mit Trend\"),\n       col=c(\"#7fc97f\", \"#beaed4\"), lty = c(1, 1))\n\n\n\n\n\nDie Evidenzakkumulierung wird analog modelliert. Wenn wir explizit die Zeitschritte als Iterationen aufschreiben, können wir dies in R mit einer for Loop machen.\n\n\nShow code\n\nn_steps <- 10\nevidence <- rep(NA, n_steps)\ndv <- rep(NA, n_steps)\n\ntime_steps <- 1:n_steps\n\n# Wir ziehen den ersten Wert aus der Verteilung\nevidence[1] <- rnorm(1, mean = driftrate, sd = sd)\ndv[1] <- evidence[1]\n\n# für jeden weitern Zeitpunkt ziehen wir wieder eine Zufallszahl und addieren zur kumulierten DV\nfor (t in 2:n_steps) {\n    evidence[t] <- rnorm(1, mean = driftrate, sd = sd)\n    dv[t] <- dv[t-1] + evidence[t]\n}\n\n\n\n\n\ntibble(time_steps, evidence, dv) %>% \n    pivot_longer(c(evidence, dv), names_to = \"type\", values_to = \"value\") %>% \n    ggplot(aes(time_steps, value, linetype = type, color = type)) +\n    geom_line() +\n    geom_point(size = 4) +\n    scale_color_viridis_d(begin = 0.2, end = 0.5)\n\n\n\n\nDie Decision Variable dv repräsentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheiung treffen kann. Wenn die Decision Variable entweder grösser als die ober Grenze ist, oder kleiner als die untere Grenze, wird die Evidenzakkumulierung abgebrochen, und eine Antwort wird ausgelöst. Wir können nun noch die “non-decision time” hinzufügen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es natürlich weniger Evindenz, um die Grenze zu erreichen, welche näher beim Anfangspunkt liegt.\nAnhand der folgenden Funktion lässt sich ein simpler Entscheidungsprozess simulieren, welcher alle wesentlichen Komponenten enthält: die drift rate, boundary separation, bias und die non-decision time ndt.\n\n\nShow code\n\ndrift_diffusion <- function(bias = 0.5,\n                            driftrate = 0.8,\n                            decision_boundary = 2,\n                            ndt = 0.5,\n                            diffvar = 0.1,\n                            dt = 0.001,\n                            max_time = 6) {\n\n    assertthat::assert_that(diffvar > 0)\n\n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias <- as.numeric(2 * decision_boundary * bias - decision_boundary)\n\n    # initialize time_steps and dv\n    time_steps <- max_time/dt\n    dv <- array(dim = time_steps)\n\n    # start acumulating from bias (starting point)\n    dv[1] <- rnorm(1, mean = bias, sd = sqrt(dt))\n\n    for (j in 2:time_steps) {\n\n        # non-decision time\n        if (j <= ndt/dt) {\n            dv[j] <- dv[j-1]\n        }\n        else {\n            error <- rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] <- dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) > decision_boundary) {\n                dv[j] <- dplyr::if_else(dv[j] > 0,\n                                 min(dv[j], decision_boundary),\n                                 max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d <- dplyr::tibble(time = round(seq_along(dv) * dt, 2),\n                         dv = dv,\n                         steps = seq_along(dv),\n                         driftrate = driftrate,\n                         decision_boundary = decision_boundary,\n                         bias = bias,\n                         ndt = ndt)\n    return(d)\n}\n\n\n\n\nEntscheidungsprozess in Pseudo-Code:\nHier ist derselbe Algorithmus wie oben, aber in Pseudo-Code, anstelle von R Code.\nWähle einen Punkt zwischen Unter- und Obergrenze. Dieser Punkt ist der bias. Wenn dieser genau 0.5 ist, sind wir auf halben Weg zwischen den Grenzen.\nZiehe Evidenz aus einer Normalverteilung mit Mittelwert 0 und addiere die Differenz zwischen 0.5 und dem bias. Hier fangen wir mit der Akkumulierung an.\nWarte bis die non-decision time vorbei ist.\nFange an, Evidenz aus einer Normalverteilung mit \\(\\mu = \\text{driftrate}\\) zu ziehen. Addiere die aktuelle Evidenz zur akkumulierten decision variable.\nWiederhole dies, bis eine der Grenzen erreicht ist.\nEntscheide dich für diejenige Alternative, dessen Grenze du erreicht hast.\n\nWir können nun einige Trials plotten, um den Effekt dieser Parameter zu visualisieren.\n\n\nlibrary(kableExtra)\ntribble(~Parameter, ~Bedeutung, ~Anwendung,\n        \"drift rate\", \"Qualität der Evidenz pro Zeiteinheit\", \"Task Schwierigkeit, Fähigkeit\",\n        \"bias\", \"Anfangspunkt der Evidenzakkumulierung\", \"A priori Präferenz für eine der beiden Alternativen\",\n        \"boundary separation\", \"Vorsicht (caution)\", \"Speed-Accuracy Trade-off\",\n        \"non'decision time\", \"Verzögerung\", \"Periphere Prozesse\") |> \n\n  kbl() |> \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nParameter\n\n\nBedeutung\n\n\nAnwendung\n\n\ndrift rate\n\n\nQualität der Evidenz pro Zeiteinheit\n\n\nTask Schwierigkeit, Fähigkeit\n\n\nbias\n\n\nAnfangspunkt der Evidenzakkumulierung\n\n\nA priori Präferenz für eine der beiden Alternativen\n\n\nboundary separation\n\n\nVorsicht (caution)\n\n\nSpeed-Accuracy Trade-off\n\n\nnon’decision time\n\n\nVerzögerung\n\n\nPeriphere Prozesse\n\n\nDrift rate\nWir fangen an mit der drift rate. Wenn diese \\(>> 0\\) ist, wird die Obergrenze schnell erreicht, und es wir wenige Fehler geben. Ist die drift rate kleiner, aber immer noch \\(> 0\\), wird die durschnittliche Zeit länger, um eine korrekte Antowort zu geben.\n\n\nShow code\n\nset.seed(829)\n\nslow <- drift_diffusion(driftrate = 0.8) %>% mutate(type = \"slow\")\nfast <- drift_diffusion(driftrate = 1.2) %>% mutate(type = \"fast\")\n\nfastslow <- bind_rows(fast, slow) \n\nfastslow %>% \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Grosse vs. kleine Drift Rate\")\n\n\n\n\nBias\nWenn der bias \\(>0.5\\) ist, wird die Obergrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate—ist diese klein, ist die Chance, schnelle Fehler zu machen erhöht.\n\n\nset.seed(29)\n\nunbiased <- drift_diffusion(bias = 0.5) %>% mutate(type = \"unbiased\")\nupbiased <- drift_diffusion(bias = 0.7) %>% mutate(type = \"upbiased\")\ndownbiased <- drift_diffusion(bias = 0.3) %>% mutate(type = \"downbiased\")\n\n\n\nbias <- bind_rows(unbiased, upbiased, downbiased) \n\nbias %>% \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Anfangspunkte\")\n\n\n\n\nBoundary separation\nLiegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies führt dazu, dass weniger Fehler gemacht werden, da die zufällige Fluktuation über längere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erklären.\n\n\nset.seed(84)\n\ncarefree <- drift_diffusion(decision_boundary = 1.6) %>% mutate(type = \"carefree\")\ncautious <- drift_diffusion(decision_boundary = 2.1) %>% mutate(type = \"cautious\")\n\ncautiouscareless <- bind_rows(carefree, cautious) \n\ndecision_boundaries <- tribble(~type, ~decision_boundary,\n                               \"carefree\", 1.6,\n                               \"cautious\", 2.1)\ncautiouscareless %>% \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +\n    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +\n    ggtitle(\"Unterschiede im Abstand zwischen den Grenzen\")\n\n\n\n\nNon-decision time\nEine Veränderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.\n\n\nset.seed(4534)\n\nlongndt <- drift_diffusion(ndt = 0.7) %>% mutate(type = \"longndt\")\nshortndt <- drift_diffusion(ndt = 0.2) %>% mutate(type = \"shortndt\")\n\nndt <- bind_rows(longndt, shortndt) \n\nndts <- tribble(~type, ~ndt,\n                \"longndt\", 0.7,\n                \"shortndt\", 0.2)\n\nndt %>% \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_viridis_d(end = 0.8) +\n    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +\n    geom_hline(yintercept = c(-2, 2), color = \"black\", size = 1) +\n    ggtitle(\"Unterschiede in der Non-Decision Time\")\n\n\n\n\nSimulationen\nDie Verteilungsfunktion sind im R Package rtdists enthalten. Damit können zum Beispiel Zufallszahlen aus der DDM Verteilung ziehen, ohne dass wir den Prozess wie oben Schritt für Schritt modellieren müssen.\n\n\nlibrary(rtdists)\n\n\n\nWir können so ein Experiment simulieren, bei dem die Fehler im Schnitt schneller als die korrekten Antworten sind, indem wir eine A Priori Präferenz für die Untergrenze definieren (z = 0.2).\nDie 5 wichtigsten Argumente der Funktion sind:\nn: Anzahl Zufallszahlen\na: boundary separation\nv: drift rate\nt0: non-decision time\nz: bias\n\n\nrts <- rdiffusion(500, a = 1, v = 2, t0 = 0.5, z = 0.2)\n\nglimpse(rts)\n\n\nRows: 500\nColumns: 2\n$ rt       <dbl> 0.9946603, 0.6598096, 0.5840942, 0.8145105, 0.74481…\n$ response <fct> upper, upper, lower, upper, upper, upper, upper, up…\n\n\n\nhead(rts)\n\n\n         rt response\n1 0.9946603    upper\n2 0.6598096    upper\n3 0.5840942    lower\n4 0.8145105    upper\n5 0.7448141    upper\n6 0.6305719    upper\n\n\n\nShow code\n\nrts %>% \n    ggplot(aes(rt, response, fill = response)) +\n    geom_violin() +\n    scale_fill_viridis_d(option = \"B\", direction = -1, \n                       begin = 1/3, end = 3/3)\n\n\n\n\n\n\nrts %>% \n    group_by(response) %>% \n    summarise(mean = mean(rt),\n              median = median(rt),\n              sd = sd(rt))\n\n\n# A tibble: 2 x 4\n  response  mean median    sd\n  <fct>    <dbl>  <dbl> <dbl>\n1 lower    0.585  0.550 0.106\n2 upper    0.767  0.724 0.159\n\nModel-based Cognitive Neuroscience\nForstmann, Ratcliff, and Wagenmakers (2016) bieten einen gut Überblick über Anwendungen des DDM in den Neurowissenschaften. Sie schreiben, dass die Verwendung eines kognitiven Prozessmodels sich besonders gut dafür eignet, individuelle Fähigkeiten zu messen, welche nicht durch die periphere Verarbeitung oder durch “response caution” kontaminiert ist.\nBeispiele\nAltern: ältere Erwachsene sind oft langsamer als jüngere, machen aber nicht mehr Fehler. DDM Resultate haben gezeigt, dass es nicht immer kognitive Fähigkeiten sind, welche mit dem alter abnehmen, sondern oftmals periphere Prozesse und grössere Vorsicht. Dies konnte in Studien zu numerosity judgments, lexical decisions und recognition memory gezeigt werden.\nArbeitsgedächtnis und IQ: ein höherer IQ geht mit einer grösserern drift rate einher.\nKlinische Studien: Patienten mit Angststörungen haben eine höhere drift rate für bedrohliche Wörter/Bilder mit bedrohlichem Inhalt.\nAnhand von DDM können Neuowissenschaftler Hirnmessungen mit kognitiven Prozessen assoziieren, anstelle von behavioralen “Effekten.” Folgende Studie ist ein gutes Beispiel einer solchen Studie, und gleichzeitig eine der ersten Model-based Neuroscience Studien.\nBias in the Brain\nMulder et al. (2012) haben untersucht, wie “prior knowledge” den Entscheidungsprozess in einem Random Dot Motion Task beeinflusst, und ob es ein neuronales Korrelat solchen Vorwissen gibt. Ein Beispielstrial ist weiter oben in diesem Kapitel dargestellt (siehe Figure 1).\nAus diesem Grund haben sie zwei verschieden Typen von Vorwissen benutzt.\nA Priori Wahrscheinlichkeit, dass die Punktwolke sich nach rechts oder nach links bewegte.\nAsymmetrische Belohnung für korrekte links/rechts Entscheidungen.\n\n\n\nFigure 3: Figure from Mulder et al. (2012)\n\n\n\nFigure 4 zeigt schematisch die erwarteten Resultate. Für den Fall, dass der starting point im DDM betroffen ist, sind Reaktionszeiten schneller und die Fehlerrate kleiner, wenn das Vorwissen valide war. Bei invalidem Vorwissen sind die Fehler schneller, korrekte Entscheidungen sind langsamer, und die Fehlerrate ist erhöht.\nWenn die draift rate betroffen wäre, würde sich dies nur im Muster der Fehler manifestieren. Um also die neuronalen Korrelate von Vorwissen in perzeptuellen Entscheidungen zu untersuchen, ist es entscheidend, vorher zu demonstrieren, ob ein Parameter betroffen ist, der vor Beginn des Trials festegelegt wurde, oder ob die Akkumulation sensorischen Evidenz betroffen war, da anzunehmen war, dass die Prozesse in unterschiedlichen Hirnarealen ablaufen.\n\n\n\nFigure 4: Figure from Mulder et al. (2012)\n\n\n\nDie Resultate zeigent, dass die beiden Manipulationen von Vorwissen sich 1) nicht unterschieden, und 2) den starting point Parameter beeinflussten, und nicht die drift rate.\nIn Figure 5 sind die BOLD Responses der Areale welche besonder stark auf die “prior probability” (oben) und auf die “payoff” Manipulation (unten) reagierten.\nDie Areale welche unabhängig der Art der Manipulation einen erhöhten BOLD Response zeigten waren der rechte MedFG (right medial frontal gyrus), ACG (anterior congulate cortex), SFG (superior frontal gyrus), left middle temporal gyrus und IPS (intra-parietal sulcus). Die Autoren schlossen, dass diese Areale eine besondere Rolle in der Verarbeitung von Bias im Entscheidungsverhalten haben, und unabhängig davon, wie dieser Bias zustande kam.\n\n\n\nFigure 5: Figure from Mulder et al. (2012)\n\n\n\nDDM mit brms\nIm letzten Teil wollen wir einen ähnlichen Datensatz wie aus dem Mulder et al. (2012) Experiment mit einem DDM analysieren. Dies können wir mit einer Verteilung tun, welche in brms und Stan implementiert ist; die wiener Verteilung. Wir beschränken uns hier auf die Daten nur einer Versuchsperson aus einem fiktiven Experiment, welches eine Vereinfach des Mulder Experiments ist. Die Versuchsperson musste sich entscheiden, ob eine Punktwolke sich nach links oder nach rechts bewegte. Vor Beginn des Trials wurde jeweils ein Cue gezeigt in Form eines Pfeils, dessen Richtung entweder kongruent (valid cue) oder inkongruent (invalid cue) mit der Stimulusrichtung war.\n\n\nlibrary(tidyverse)\nlibrary(rtdists)\nlibrary(brms)\n\n\n\nWir generieren hier die Daten mit bekannten Parametern, damit wir wissen, ob wir diese rekonstruieren können. Die drift rate v, boundary separation a und non-decision time ndt bleiben in den beiden Bedingugen konstant. In der valid cue Bedingungen hat der starting point z den Wert \\(0.8\\)—in der invalid cue Bedingung den Wert \\(0.2\\). Wir simulieren in jeder Bedingung 100 Trials.\n\n\nv <-  0.5  # average driftrate\na <- 1.0   # average boundary separation\nndt <- 0.3    # average non-decision time\n\nntrials <- 100 # 100 Trials pro Bedingung\n\n\n\n\n\nShow code\n\nd_valid<- tibble(rdiffusion(ntrials, a = a, v = v, z = 0.8, t0 = ndt),\n                          cue = \"valid\")\nd_invalid <- tibble(rdiffusion(ntrials, a = a, v = v, z = 0.2, t0 = ndt),\n                          cue = \"invalid\")\n\nd <- rbind(d_valid, d_invalid) |> \n  mutate(cue = as_factor(cue))\n\nglimpse(d)\n\n\nRows: 200\nColumns: 3\n$ rt       <dbl> 0.3395435, 0.3041726, 0.6660463, 0.3255624, 0.45590…\n$ response <fct> upper, upper, upper, upper, lower, upper, upper, up…\n$ cue      <fct> valid, valid, valid, valid, valid, valid, valid, va…\n\n\n\nShow code\n\nd |>\n    mutate(response = ifelse(response == \"upper\", \n                             \"correct\", \"error\"),\n           cue = ifelse(cue == \"valid\", \"valid cue\",\n                        \"invalid cue\")) |> \n    ggplot(aes(rt, fill = response)) +\n    geom_density() +\n    geom_rug() +\n    scale_color_brewer(type = \"qual\") +\n    scale_fill_brewer(type = \"qual\") +\n    facet_grid(response ~ cue) +\n  theme(legend.position = \"none\")\n\n\n\n\nDie Daten zeigen den Effekt, dass die Fehler in der valid cue Bedingung langsamer als die korrekten Entscheidungen sind, während die Fehler in der invalid cue Bedingung schneller sind.\nWir wissen, dass sich zwischen den Bedingungen nur der bias verändert. Wenn wir die Daten jedoch nicht selber generieren, würden wir wahrscheinlich davon ausgehen, dass sich sowohl die drift rate als auch der bias zwischen den Bedingungen unterscheiden könnte.\nNun müssen wir beachten, dass die Wiener Verteilung in brms 4 Parameter hat, und wir zwei davon vorhersagen möchten. Deshalb verwenden wir die Funktion bf(), umd die verschiedenen Teile der Formel zu verbinden.\nDer erste Teil, rt | dec(response) ~ 0 + cue bedeudet, dass wir den Erartungswert der drift rate vohersagen, mit je einem Parameter für die beiden Bedingunen. Mit dem yweiten Teil, bias ~ 0 + cue, erreichen wir dasselbe für den bias.\n\n\nformula <- bf(rt | dec(response) ~ 0 + cue,\n              bias ~ 0 + cue)\n\n\n\n\n\nget_prior(formula, family = wiener(), data = d) |> \n  as_tibble() |> \n  select(1:4)\n\n\n# A tibble: 8 x 4\n  prior               class coef         group\n  <chr>               <chr> <chr>        <chr>\n1 \"\"                  b     \"\"           \"\"   \n2 \"\"                  b     \"cueinvalid\" \"\"   \n3 \"\"                  b     \"cuevalid\"   \"\"   \n4 \"gamma(1, 1)\"       bs    \"\"           \"\"   \n5 \"uniform(0, min_Y)\" ndt   \"\"           \"\"   \n6 \"\"                  b     \"\"           \"\"   \n7 \"\"                  b     \"cueinvalid\" \"\"   \n8 \"\"                  b     \"cuevalid\"   \"\"   \n\nDa wir hier sowohl die drafit rate als auch den bias mit einem linearen Modell vorhersagen, haben die Koeffizienten flache Prior. Wir benutzen lieber eigene Priors—in beiden Fällen Normalverteilungen mit \\(\\mu = 0\\) und \\(\\sigma = 1\\), da wir keine grossen Werte für die Parameter erwarten können.\n\n\npriors <- prior(normal(0, 1), class = b) +\n    prior(normal(0, 1), class = b, dpar = bias)\n\n\n\n\n\nfit <- brm(formula,\n            prior = priors,\n            family = wiener(link = \"identity\", link_bias = \"logit\"),\n            data = d,\n            file = \"models/ddm1\")\n\n\n\n\n\nfit\n\n\n Family: wiener \n  Links: mu = identity; bs = identity; ndt = identity; bias = logit \nFormula: rt | dec(response) ~ 0 + cue \n         bias ~ 0 + cue\n   Data: d (Number of observations: 200) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\ncuevalid            0.32      0.27    -0.21     0.83 1.00     3789\ncueinvalid          0.62      0.25     0.14     1.12 1.00     3575\nbias_cuevalid       1.32      0.12     1.09     1.55 1.00     2620\nbias_cueinvalid    -1.31      0.13    -1.55    -1.05 1.00     2522\n                Tail_ESS\ncuevalid            2942\ncueinvalid          3066\nbias_cuevalid       2805\nbias_cueinvalid     2639\n\nFamily Specific Parameters: \n    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nbs      1.04      0.04     0.97     1.12 1.00     3560     2672\nndt     0.30      0.00     0.30     0.30 1.00     2728     2745\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nmcmc_plot(fit)\n\n\n\n\nDie beiden Parameter bias_cuevalid und bias_cueinvalid sind auf der log-odds Skala. Deis bedeutet, dass Werte > 0 eine Präferenz für die Obergrenze darstellen. Wenn wir die Werte auf der bias-Skala (als Wert zwischen den Grenzen) haben wollen, müssen wir sie mit plogis() transformieren, genau wie bei der logistischen Regression.\nMit fixef() erhalten wir eine Zusammenfassung, welche wir wieder in Werte zwischen 0 und 1 konvertieren können.\n\n\nfixef(fit, pars = c(\"bias_cuevalid\", \"bias_cueinvalid\")) |> \n  plogis()\n\n\n                 Estimate Est.Error      Q2.5     Q97.5\nbias_cuevalid   0.7900052 0.5296627 0.7490201 0.8254932\nbias_cueinvalid 0.2130513 0.5317967 0.1745968 0.2592626\n\n\nStreng genommen ist dies nicht korrekt, denn eigentlich müssten wir die Posterior Samples zuerst transformieren, und erst dann zusammenfassen.\nResultat\nWir können die wahren bias Parameter ziemlich gut schätzen, aber aufgrund der wenigen Trials ist die Schätzung nicht sehr genau (100 Trials pro Bedingung sind für ein DDM nicht sehr viele).\nAusserdem wird die drift rate unterschiedlich pro Bedingung geschätzt. Dies ist eher ungünstig, da wir wissen, dass nur der bias sich zwischen den Bedingungen geändert hat.\nIn einer Studie wäre es sinnvoller, zwei Modelle zu schätzen, eines davon mit unterschiedlichen drift rates, das andere mit unterschiedichen bias Parametern, und die beiden Modell dann zu vergleichen.\nWir schätzen hier den bias für diese Versuchsperson in den beiden Cue Bedingungen, und stellen fest, dass diesse Versuchsperson eine starke a priori Präferenz für korrekte Entscheidungen hat, wenn der Cue valide war, das heisst wenn die Richtungen des Pfeils und des Stimulus gleich waren. Wir könnten nun diese individuellen bias Parameter in einer fMRI Untersuchung benutzen, um herauszufinden, in welche Hirnregionen erhöhte BOLD Aktivität sich mit den personenspezifischen Parametern vorhersagen lässt.\n\n\n\nForstmann, B. U., R. Ratcliff, and E.-J. Wagenmakers. 2016. “Sequential Sampling Models in Cognitive Neuroscience: Advantages, Applications, and Extensions.” Annual Review of Psychology 67 (1): 641–66. https://doi.org/10.1146/annurev-psych-122414-033645.\n\n\nMulder, M. J., E.-J. Wagenmakers, R. Ratcliff, W. Boekel, and B. U. Forstmann. 2012. “Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff.” Journal of Neuroscience 32 (7): 2335–43. https://doi.org/10.1523/JNEUROSCI.4156-11.2012.\n\n\nRatcliff, Roger, and Gail McKoon. 2008. “The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks.” Neural Computation 20 (4): 873–922. https://doi.org/10.1162/neco.2008.12-06-420.\n\n\nVinding, Mikkel C., Jonas Kristoffer Lindeløv, Yahui Xiao, Raymond C. K. Chan, and Thomas Alrik Sørensen. 2018. “Volition in Prospective Memory: Evidence Against Differences in Recalling Free and Fixed Delayed Intentions,” December. https://doi.org/10.31234/osf.io/hsrbt.\n\n\n\n\n",
      "last_modified": "2021-06-01T03:04:08+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
