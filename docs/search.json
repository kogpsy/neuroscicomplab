{
  "articles": [
    {
      "path": "01-intro-bayesian-stats.html",
      "title": "Einführung",
      "description": "Klassische (frequentistische) und Bayesianische Statistik.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nKlassische (frequentistische) Statistik\nBeispiel: t-Test\nWeitere Probleme\nPhilosophie der Wahrscheinlichkeit\n\nBayesianische Statistik\nDegrees of belief\nGrundlagen der Bayesianischen Inferenz\nParameterschätzung: Wahrscheinlichkeitsparameter einer Binomialverteilung\nBayes’ Theorem\nBeta Verteilung\nEinfluss des Priors auf den Posterior\nSchätzmethoden\nStan\nbrms\nPosterior-Verteilungen zusammenfassen\nWeiterführende Literatur\n\n\nKlassische (frequentistische) Statistik\nIm Verlauf Ihres bisherigen Studiums haben Sie verschiedene statistische Methode kennengelernt, die alle etwas mit Null Hypothesis Significance Testing (NHST) zu haben. Diese Verfahren haben gemeinsam, dass sie\nPunktschätzungen von Parametern benutzen\nmit diesen Punktschätzungen eine Teststatistik erstellen\ndie Wahrscheinlichkeit angeben, mit derer eine mindestens so extreme Ausprägung dieser Teststatistik erreicht wird, unter der Annahme, dass die Nullhypothese wahr ist. Diese Wahrscheinlichkeit nennt man einen p-Wert.\nDiese Methoden stehen schon seit längerem in der Kritik:\nGigerenzer (2004);Gigerenzer (2018) behauptet unter anderem, dass die Verwendung von NHST Methoden oftmals einem statistischen Ritual gleichkommt.\nWasserstein and Lazar (2016) schreiben im Statement on Statistical Significance and P-Values der American Statistical Association:\nP-values can indicate how incompatible the data are with a specified statistical model.\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\n\nEs scheint also grosse Probleme mit dem Verständnis von Konzepten der klassischen Statistik zu geben. Zum Beispiel werden Grundlegende Konzepte wie p-Werte und Konfidenzintervalle oft falsch verstanden (Hoekstra et al. 2014).\nBeispiel: t-Test\nSchauen wir uns das Beispiel der letzten Sitzung nochmals an. Wir haben einen Datensatz generiert, um zwei geschätzte Mittelwerte zu vergleichen, mit dem Ziel herauszufinden, ob eine Gruppe einen grösseren Mittelwert als die andere hat.\n\n\nlibrary(tidyverse)\nlibrary(kableExtra)\n\nset.seed(12)\n\n# Number of people wearing fancy hats\nN_fancyhats <- 50 \n\n# Number of people not wearing fancy hats\nN_nofancyhats <- 50\n\n# Population mean of creativity for people wearing fancy hats\nmu_fancyhats <- 103 \n\n# Population mean of creativity for people wearing no fancy hats\nmu_nofancyhats <- 98 \n\n# Average population standard deviation of both groups\nsigma <- 15 \n\n# Generate data\nfancyhats = tibble(Creativity = rnorm(N_fancyhats, mu_fancyhats, sigma),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(N_nofancyhats, mu_nofancyhats, sigma),\n                 Group = \"No Fancy Hat\")\n\n\nFancyHat <- bind_rows(fancyhats, nofancyhats)  %>%\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\n\n\nDie Daten sehen so aus:\n\n\nkbl(FancyHat) %>%\n  kable_paper() %>%\n  scroll_box(width = \"500px\", height = \"200px\")\n\n\n\n\nCreativity\n\n\nGroup\n\n\n80.79149\n\n\nFancy Hat\n\n\n126.65754\n\n\nFancy Hat\n\n\n88.64883\n\n\nFancy Hat\n\n\n89.19992\n\n\nFancy Hat\n\n\n73.03537\n\n\nFancy Hat\n\n\n98.91556\n\n\nFancy Hat\n\n\n98.26977\n\n\nFancy Hat\n\n\n93.57617\n\n\nFancy Hat\n\n\n101.40304\n\n\nFancy Hat\n\n\n109.42022\n\n\nFancy Hat\n\n\n91.33421\n\n\nFancy Hat\n\n\n83.59177\n\n\nFancy Hat\n\n\n91.30650\n\n\nFancy Hat\n\n\n103.17928\n\n\nFancy Hat\n\n\n100.71376\n\n\nFancy Hat\n\n\n92.44804\n\n\nFancy Hat\n\n\n120.83319\n\n\nFancy Hat\n\n\n108.10768\n\n\nFancy Hat\n\n\n110.60452\n\n\nFancy Hat\n\n\n98.60042\n\n\nFancy Hat\n\n\n106.35462\n\n\nFancy Hat\n\n\n133.10802\n\n\nFancy Hat\n\n\n118.17969\n\n\nFancy Hat\n\n\n98.46311\n\n\nFancy Hat\n\n\n87.62133\n\n\nFancy Hat\n\n\n98.98923\n\n\nFancy Hat\n\n\n100.01342\n\n\nFancy Hat\n\n\n104.96684\n\n\nFancy Hat\n\n\n105.18700\n\n\nFancy Hat\n\n\n108.43097\n\n\nFancy Hat\n\n\n113.10972\n\n\nFancy Hat\n\n\n134.08054\n\n\nFancy Hat\n\n\n94.88457\n\n\nFancy Hat\n\n\n86.94262\n\n\nFancy Hat\n\n\n97.41315\n\n\nFancy Hat\n\n\n95.72288\n\n\nFancy Hat\n\n\n107.12176\n\n\nFancy Hat\n\n\n95.80731\n\n\nFancy Hat\n\n\n114.97158\n\n\nFancy Hat\n\n\n87.93323\n\n\nFancy Hat\n\n\n104.57476\n\n\nFancy Hat\n\n\n85.66011\n\n\nFancy Hat\n\n\n111.67202\n\n\nFancy Hat\n\n\n79.06562\n\n\nFancy Hat\n\n\n98.37245\n\n\nFancy Hat\n\n\n109.74199\n\n\nFancy Hat\n\n\n88.34420\n\n\nFancy Hat\n\n\n105.84997\n\n\nFancy Hat\n\n\n113.97180\n\n\nFancy Hat\n\n\n95.61101\n\n\nFancy Hat\n\n\n97.35973\n\n\nNo Fancy Hat\n\n\n96.30994\n\n\nNo Fancy Hat\n\n\n104.85241\n\n\nNo Fancy Hat\n\n\n128.30502\n\n\nNo Fancy Hat\n\n\n82.23665\n\n\nNo Fancy Hat\n\n\n109.01978\n\n\nNo Fancy Hat\n\n\n106.08875\n\n\nNo Fancy Hat\n\n\n78.28591\n\n\nNo Fancy Hat\n\n\n94.24942\n\n\nNo Fancy Hat\n\n\n102.71307\n\n\nNo Fancy Hat\n\n\n104.09820\n\n\nNo Fancy Hat\n\n\n112.91631\n\n\nNo Fancy Hat\n\n\n110.83653\n\n\nNo Fancy Hat\n\n\n100.95693\n\n\nNo Fancy Hat\n\n\n110.51488\n\n\nNo Fancy Hat\n\n\n110.70185\n\n\nNo Fancy Hat\n\n\n127.31158\n\n\nNo Fancy Hat\n\n\n65.76110\n\n\nNo Fancy Hat\n\n\n112.56680\n\n\nNo Fancy Hat\n\n\n115.17592\n\n\nNo Fancy Hat\n\n\n90.11899\n\n\nNo Fancy Hat\n\n\n101.75480\n\n\nNo Fancy Hat\n\n\n91.55890\n\n\nNo Fancy Hat\n\n\n95.26221\n\n\nNo Fancy Hat\n\n\n96.45034\n\n\nNo Fancy Hat\n\n\n88.49243\n\n\nNo Fancy Hat\n\n\n78.93419\n\n\nNo Fancy Hat\n\n\n92.24074\n\n\nNo Fancy Hat\n\n\n105.75134\n\n\nNo Fancy Hat\n\n\n95.33047\n\n\nNo Fancy Hat\n\n\n98.06387\n\n\nNo Fancy Hat\n\n\n78.88911\n\n\nNo Fancy Hat\n\n\n94.96834\n\n\nNo Fancy Hat\n\n\n115.46699\n\n\nNo Fancy Hat\n\n\n97.64931\n\n\nNo Fancy Hat\n\n\n111.45735\n\n\nNo Fancy Hat\n\n\n95.34913\n\n\nNo Fancy Hat\n\n\n114.70564\n\n\nNo Fancy Hat\n\n\n89.87167\n\n\nNo Fancy Hat\n\n\n83.54903\n\n\nNo Fancy Hat\n\n\n103.64673\n\n\nNo Fancy Hat\n\n\n83.22989\n\n\nNo Fancy Hat\n\n\n111.46339\n\n\nNo Fancy Hat\n\n\n99.93894\n\n\nNo Fancy Hat\n\n\n113.50554\n\n\nNo Fancy Hat\n\n\n92.86566\n\n\nNo Fancy Hat\n\n\n104.78422\n\n\nNo Fancy Hat\n\n\n87.57893\n\n\nNo Fancy Hat\n\n\n94.41480\n\n\nNo Fancy Hat\n\n\n82.89052\n\n\nNo Fancy Hat\n\n\n\nUnd grafisch dargestellt (als Boxplot):\n\n\n# plot both groups\nFancyHat %>% \n    ggplot() +\n    geom_boxplot ((aes(y = Creativity, x = Group))) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nUnter der Annahme, dass die beiden Gruppen dieselbe Standardabweichung haben, machen wir einen t-Test:\n\n\nfancyhat_ttest <- t.test(Creativity ~ Group,\n       var.equal = TRUE,\n       data = FancyHat)\n\n\n\n\n\nfancyhat_ttest_tab <- broom::tidy(fancyhat_ttest)\n\n\n\n\n\nfancyhat_ttest_tab %>%\n    select(estimate, estimate1, estimate2, statistic, p.value, conf.low, conf.high) %>%\n    round(3) %>% \n    kbl() %>%\n    kable_classic(full_width = FALSE, html_font = \"Cambria\")\n\n\n\nestimate\n\n\nestimate1\n\n\nestimate2\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\n-1.647\n\n\n99.209\n\n\n100.856\n\n\n-0.637\n\n\n0.526\n\n\n-6.78\n\n\n3.486\n\n\nEs ist vielleicht nicht ganz offensichtlich, dass wir hier mehrere Dinge gemacht haben:\nWir haben zwei Mittelwerte geschätzt. Genauer gesagt haben wir zwei Punktschätzungen der Gruppenmittelwerte1.\nWir schätzen die resultierende Differenz der Gruppenmittelwerte2.\nWir berechnen eine Teststatistik (empirischer t-Wert)3.\nWir berechnen die Wahrscheinlichkeit, unter der Nullhypothese einen t-Wert zu erhalten, der einen mindestens so grossen Betrag hat wie der empirische t-Wert4.\n\nDiskutieren Sie die Bedeutung des erhalten p-Wertes und des Konfidenzintervalles. Finden Sie diese Konzepte intuitiv verständlich? Können Sie erklären, was ein Konfidenzintervall ist?\nDer p-Wert beträgt 0.53. Was können wir damit anfangen?\n\nWeitere Probleme\nEs gibt viele weitere Probleme mit dem frequentistischen Ansatz (Wagenmakers 2007)—die oben genannten haben damit zu tun, dass die Konzepte nicht sonderlich intuitiv sind. Wir hätten z.B. gerne die Wahrscheinlichkeit, mit der eine Hypothese wahr/falsch ist.\n\nfrequentische Statistik kann eine solche Aussage prinzipiell nicht machen.\nEin weiteres Problem ist, dass Anreize in der Forschung oftmals dazu verleiten, frequentistische NHST falsch einzusetzen. Verschiedene bad practices sind unter dem Begriff p-hacking bekannt. Damit kann z.B. gemeint sein, viele Hypothesentests durchzuführen, aber nur diejenigen zu Berichten, welche ein signifikantes Resultat ergeben.\nSchlussendlich ist auch so, dass frequentistische Statistik nicht den von den Axiomen der Wahrscheinlichkeitstheorie Gebrauch macht, um Parameter zu schätzen, und die Unsicherheit bei der Schätzung nicht anhand einer Wahrscheinlichkeitsverteilung quantifiziert.\nPhilosophie der Wahrscheinlichkeit\nIn der klassischen Statistik wird Wahrscheinlichkeit als relative Häufigkeits eines Ereignisses verstanden. Dies bedeutet, dass nur Ereignisse, welche (unendlich) oft wiederholt werden können, eine Wahrscheinlichkeit haben können.\nSomit ist es unmöglich, dass Parameter oder Hypothesen eine Wahrscheinlichkeitsverteilung haben können. Zum Vergleich von frequentistischer und Bayesianischer Auffassung von Wahrscheinlichkeiten gibt es hier und hier mehr Information.\nBayesianische Statistik\nDegrees of belief\nWir werden nun mit einem anderen Ansatz arbeiten. Dieser beruht auf den Axiomen der Wahrscheinlichkeitstheorie, und auf der Auffassung von Wahrscheinlichkeit als degree of belief, also vom der Grad persönlichen Überzeugung. Daher wird dieser Ansatz of subjektiv genannt.\n\nMeiner Meinung nach ist diese philosophische Diskussion über Interpretationen der Wahrscheinlichkeitstheorie nicht besonders zielführend. Wir können die unterschiedlichen Meinungen einfach zur Kenntnis nehmen.\n\nDie wichtigste Erkenntnis ist jedenfalls: Wahrscheinlichkeitsverteilungen quantifizieren unseren Wissensstand, oder genauer gesagt, unsere Unsicherheit (uncertainty) über etwas. Dies kann eine Aussage sein, wie z.B. “es wird morgen regnen,” oder ein Parameter in einem statistischen Modell, oder eine Hypothese.\n\nDie in 1 abgebildeten Verteilungen zeigen unsere Unsicherheit über eine Variable \\(x\\). Wir wissen, dass \\(x>0\\), und wir vermuten, dass \\(x<50\\). In einem Fall (violette Verteilung) glauben wir sogar mit einiger Sicherheit, dass \\(x<10\\).\n\n\nlibrary(tidyverse)\n\ntibble(x = seq(from = 0, to = 60, by = .1)) %>% \n  expand(x, nesting(alpha = c(2, 4), \n                    beta  = c(0.1, 1))) %>% \n  mutate(density = dgamma(x, alpha, beta),\n         group   = rep(letters[1:2], times = n() / 2)) %>% \n  \n  ggplot(aes(x = x, ymin = 0, ymax = density, \n             group = group, fill = group)) +\n  geom_ribbon(size = 0, alpha = 3/4) +\n  scale_fill_viridis_d(option = \"B\", direction = -1, \n                       begin = 1/3, end = 2/3) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme(panel.grid = element_blank(),\n        legend.position = \"none\")\n\n\n\n\nFigure 1: Wahrscheinlichkeitsverteilungen\n\n\n\nIn der Bayesianischen Statistik erhalten wir anstatt Punktschätzungen von Parametern ganze Verteilungen, mit denen wir unsere Unsicherheit quantifizieren. Ganz stark vereinfacht brauchen wir in der Bayesianischen Statistik eine Prior-Verteilung Englisch: prior), und wir erhalten eine Posteriori-Verteilung (Englisch: posterior), nachdem wir unseren prior anhand der Daten (likelihood) angepasst haben.\n\nUnser prior gibt an, was wir glauben, bevor wir die Daten berücksichtigen, und unser posterior gibt an, was wir glauben, nachdem wir die Daten gesehen haben.\n\nBayesianische Statistik erfordert also ein paar neue Konzepte, aber längerfristig ist dieser Ansatz einfacher, denn es beruht alles auf ein paar wenigen Grundsätzen.\nDie Vorteile des Bayesianischen Ansatzes sind:\nintuitiveres Verständnis von Unsicherheit.\nerlaubt es uns Evidenz für oder gegen Hypothesen zu quantifizieren.\ndieser Ansatz ist viel flexibler.\nWir können unser Wissen in Form von a priori-Verteilungen miteinbeziehen.\nbesser geeignet für Multilevel Modelle.\n Bayesianische Statistik hat aber auch Nachteile:\nwir brauchen leistungsstarke Computer.\nsetzt Familiarität mit Wahrscheinlichkeitsverteilungen voraus.\nes ist nicht einfach, Hypothesentests durchzuführen. Siehe z.B. hier und hier.\n\nWarum brauchen wir viel Rechenpower, um Bayesianische Statistik zu machen?\nDies hat damit zu tun, dass es nur in ganz wenigen Fällen einfach ist, posterior Verteilungen zu erhalten. In wenigen Fällen ist es möglich, diese analytisch zu bestimmen, in den den meisten Fällen brauchen wir simulationsbasierte Sampling-Verfahren (Markov Chain Monte Carlo Sampling), um die komplexen Wahrscheinlichkeitsverteilungen zu schätzen. Dies erfordert sehr schnelle Prozessoren, und war deshalb in der Vergangenheit nur auf Supercomputern möglich.\n\n\nDas ist einer der wichtigsten Gründe, weshalb die frequentistische Statistik so lange die einzige anwendbare Lösung war.\nWir werden nun anhand zweier einfacher Beispiele die Bayesianische Parameterschätzung kennenlernen. Danach werden wir komplexere Beispiele betrachten, und Methoden kennenlernen, mit denen wir Hypothesen testen können. Hypothesentests sind eine Form von Modellvergleichen, und hier gibt es mehrere Möglichkeit.\n\nWir werden machen, was Gigerenzer (2018) verlangt, und einen statistical toolkit lernen, der weit über den Einsatz von Ritualen hinausgeht!\nGrundlagen der Bayesianischen Inferenz\nParameter sind Zufallsvariablen\nParameters sind Zufallsvariablen, im Gegensatz zum frequentistischen Ansatz, in dem Parameter keine Verteilung haben können.\nParameter kommen aus Wahrscheinlichkeitsverteilung, welche unser Wissen (Unsicherheit) repräsentieren\nDie Prior-Verteilung wird anhand der Likelihood (Daten) updated, um ein Posterior-Verteilung zu erhalten.\nDrei Schritte der Bayesianischen Datenanalyse\nIm Prinzip folgt Bayesianische Datenanalyse immer den folgenden drei Schritten:\nWir schreiben ein Wahrscheinlichkeitsmodell auf, bestehen aus einer gemeinsamen Verteilung der beobachtent Variablen (\\(y\\), \\(x\\)) und der latenten Parameter \\(\\theta\\)).\nWir berechnen die Posterior-Verteilung \\(P(θ | y) \\sim P(y | \\theta) \\cdot p(\\theta)\\), bedingt auf die beobachteten Daten.\nWir evaluieren das Modell und die Posterior-Verteilung.\nWie gut passt das Modell?\nSind unsere Schlussfolgerungen gerechtfertigt?\nWie empfindlich sind unsere Schätzungen gegenüber unseren Annahmen?\nMüssen wir unser Modell revidieren?\nWir können anhand von Modellvergleichen Hypothesen testen.\n\nParameterschätzung: Wahrscheinlichkeitsparameter einer Binomialverteilung\nWir schauen uns nun diesen Prozess anhand eines simplen Beispiels an.\nBeispiel\nZwei Kartenspieler spielen gegeneinander. Sie beobachten, dass Spielerin A 6 von 9 Spielen gewinnt, während Spielerin B nur 3 davon gewinnt. Sie fragen sich nun, ob das nur Glück ist, oder ob Spielerin A tatsächlich besser sein könnte.\n\nDieses Beispiel ist analytisch lösbar. Ich werde die analytische Lösung in einem Blog Post demonstrieren, da wir hier eine simulationsbasierte Lösung anstreben.\n\nWenn Sie diesen Sachverhalt quantifizieren möchten, könnten Sie behaupten, dass die Wahrscheinlichkeit, dass Spielerin A gewinnt, grösser als 0.5 sein müsste, falls diese besser ist. Eine Wahrscheinlichkeit von 0.5 würde bedeuten, dass beide mit gleicher Wahrscheinlichkeit gewinnen.\nUnser Ziel ist es also, den Wahrscheinlichkeitsparameter \\(\\theta\\) einer Binomialverteilung zu schätzen. Die Daten, \\(y\\), sind in diesem Fall die 6 Erfolge in 9 Versuchen.\n\n\nwins <- 6\ngames <- 9\n\n\n\nWir wissen, dass die Anzahl Erfolge in k Spielen einer Binomialverteilung folgt. Falls beide Spielerinnen gleich gut sind, sollte die Erfolgswahrscheinlichkeit ungefähr 0.5 sein. Wir können die Wahrscheinlichkeit berechnen, dass Spielerin A durch Glück 6 Spiele gewinnt, d.h. unter der Annahme, dass beide gleich gut sind.\n\n\ndbinom(x = wins, size = games, prob = 0.5)\n\n\n[1] 0.1640625\n\nDiese Wahrscheinlichkeit ist ziemlich hoch. Wir können auch die kumulative Wahrscheinlichkeit berechnen, 5 mal oder weniger zu gewinnen:\n\n\npbinom(q = 5, size = games, prob = 0.5)\n\n\n[1] 0.7460937\n\nDie Wahrscheinlichkeit, 6, 7, 8 oder 9 mal zu gewinnen wäre demnach:\n\n\n1 - pbinom(q = 5, size = games, prob = 0.5)\n\n\n[1] 0.2539063\n\noder\n\n\npbinom(q = 5, size = games, prob = 0.5, lower.tail = FALSE)\n\n\n[1] 0.2539063\n\n\nWas haben wir hier berechnet? Was könnten wir hier mit einem frequentistischen Ansatz machen?\nWir können aber auch eine Punktschätzung der Wahrscheinlichkeit erhalten.\n\n\ntheta <- wins/games\ntheta\n\n\n[1] 0.6666667\n\nDies entspricht derjenigen Schätzung, für welche die Wahrscheinlichkeit maximiert wird, diese Daten zu beobachten. Dies nennt man eine Maximum Likelihood Schätzung.\n\n\ntibble(x = seq(from = 0, to = 1, by = .01)) %>% \n  mutate(density = dbinom(6, 9, x)) %>% \n  \n  ggplot(aes(x = x, ymin = 0, ymax = density)) +\n  geom_ribbon(size = 0, alpha = 1/4, fill = \"steelblue\") +\n  geom_vline(xintercept = theta, linetype = 2, size = 1.2) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 1)) +\n  xlab(\"Wahrscheinlichkeit\") +\n  theme(panel.grid = element_blank(),\n        legend.position = \"none\")\n\n\n\n\nFigure 2: Maximum-Likelihood Schätzung\n\n\n\nGrafik 2 zeigt, dass \\(\\theta\\) = 6/9 derjenige Parameter ist, für den die Wahrscheinlichkeit maximiert wird, dass wir 6 Erfolge in 9 Spielen beobachten.\nBayes’ Theorem\nMit einer Punktschätzung können wir unsere Unsicherheit aber nicht quantifizieren—dafür brauchen wir eine Verteilung über den ganzen Bereich der möglichen Parameterwerte. Diese Verteilung erhalten wir, indem wir das Bayes’sche Theorem anwenden. Die Wahrscheinlichkeit, dass A gewinnt, \\(\\theta\\), bedingt auf die Daten, ist:\n\\[ P(\\theta|Data) = \\frac{ P(Data|\\theta) * P(\\theta) } {P(Data)}\\] Der Term \\(P(Data)\\) ist eingentlich nur eine Normalisierungskonstante, welche dafür sorgt, dass wir eine Verteilung erhalten (welche zu 1 integriert), und wird oft weggelassen:\n\\[ P(\\theta|Data) \\propto P(Data|\\theta) * P(\\theta) \\] Um dies zu berechnen, brauchen wir \\(P(Data|\\theta)\\) und \\(P(\\theta)\\). \\(P(Data|\\theta)\\) ist einfach; die Wahrscheinlichkeit \\(k\\) Erfolge in \\(n\\) Versuchen zu erhalten ist\n\\[ P(x = k) = {n \\choose k} \\theta^k (1-\\theta)^{n-k} \\] Das bedeutet: \\(k\\) Erfolge mit Wahrscheinlichkeit \\(\\theta^k\\) und \\(n-k\\) Misserfolge mit Wahrscheinlichkeit \\(1-\\theta^{n-k}\\). Mit dem Term \\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\) berücksichtigen wir alle Reihenfolgen, mit denen wir 6 Erfolge in 9 Spielen erhalten.\n\\(P(\\theta)\\) ist die a-priori-Wahrscheinlichkeit, mit der Spielerin A gewinnt. Wenn wir nicht über die beiden Spielerinnen wissen, ist es sinnvoll anzunehmen, dass alle Wahrscheinlichkeiten zwischen 0 und 1 gleichwahrscheinlich sind. So eine Verteilung nennt man eine uniforme Verteilung über dem Interval \\(\\left(0, 1\\right) = \\{x \\in \\mathbb{R} | 0 < x < 1 \\}\\).\nWir definieren nun einen Vektor von möglichen Werten:\n\n\nn_points <- 100\np_grid <- seq( from=0 , to=1 , length.out = n_points )\n\n\n\nDie Likelihood, das heisst die Wahrscheinlichkeit der Daten für jeden möglichen Parameterwert, ist\n\n\nlikelihood <- dbinom(wins , size = games , prob = p_grid)\n\n\n\n\n\ncompute_posterior = function(likelihood, prior){\n  # compute product of likelihood and prior\n  unstandardized_posterior <- likelihood * prior\n  \n  # standardize the posterior, so it sums to 1\n  posterior <- unstandardized_posterior / sum(unstandardized_posterior)\n  \n  par(mfrow=c(1, 3))\n  plot(p_grid , prior, type=\"l\", main=\"Prior\", col = \"dodgerblue3\", lwd = 2)\n  plot(p_grid , likelihood, type=\"l\", main=\"Likelihood\", col = \"firebrick3\", lwd = 2)\n  plot(p_grid , posterior , type=\"l\", main=\"Posterior\", col = \"darkorchid3\", lwd = 2)\n}\n\n\n\n\n\nprior1 <- rep(0.5 , length(p_grid))\ncompute_posterior(likelihood, prior1)\n\n\n\n\nDa wir jeden Wert für gleich wahrscheinlich hielten, hat unser Prior keinen Einfluss auf den Posterior.\nWir können aber unser Vorwissen auch anders ausdrücken. Vielleicht halten wir es für möglich, dass A besser ist als B, aber wir glauben, es sei unmöglich, dass B besser ist. Dieser Glaube könnte durch folgenden Prior repräsentiert werden.\n\n\nprior2 <- ifelse(p_grid < 0.5 , 0 , 1)\ncompute_posterior(likelihood, prior2)\n\n\n\n\nDies führt dazu, dass in unserem Posterior Werte \\(< 0.5\\) nicht möglich sind, weil wir dieses Vorwissen in unserem Prior spezifiziert hatten.\nWir können aber auch abenteuerliche Priors benutzen, wie z.B. folgender: Wir glauben, dass \\(0.5\\) der wahrscheinlichste Wert ist, mit einem exponentiellen Abfall auf beide Seiten.\n\n\nprior3 <- exp(-10 * abs(p_grid - 0.5))\ncompute_posterior(likelihood, prior3)\n\n\n\n\nBeta Verteilung\nDa wir aber nicht immer unsere Prior Verteilungen per Hand spezifieren können oder wollen, ist es oft ratsam, eine bekannte Wahrscheinlichkeitsverteilung zu benutzen. Diese muss einen Wertebereich haben, der für den zu schätzenden Parameter angemessen ist. In diesem Fall ist dies das Interval \\(\\left(0, 1\\right)\\).\nDie Familie von Verteilungen, die hier in Frage kommen, sind die Beta-Verteilungen. Diese haben zwei Parameter, \\(\\alpha\\) und \\(\\beta\\), welche als Vorwissen über Erfolge und Misserfolge interpretiert werden können. Die Anzahl Versuche ist somit \\(\\alpha + \\beta\\). Diese Familie von Verteilungen kann je Nach Wahl der beiden Parameter unterschiedliche Formen annehmen. In Grafik 3 sind einige dargestellt.\n\n\nlength <- 1e4\nd <- crossing(shape1 = c(.1, 1:4),\n           shape2 = c(.1, 1:4)) %>%\n  expand(nesting(shape1, shape2),\n         x = seq(from = 0, to = 1, length.out = length)) %>% \n  mutate(a = str_c(\"a = \", shape1),\n         b = str_c(\"b = \", shape2),\n         group = rep(1:length, each = 25))\n\n\n\n\n\nd %>% \n  ggplot(aes(x = x, group = group)) +\n  \n  geom_line(aes(y = dbeta(x, shape1 = shape1, shape2 = shape2)),\n            color = \"steelblue4\", size = 1.1) +\n  scale_x_continuous(expression(theta), breaks = c(0, .5, 1)) +\n  coord_cartesian(ylim = c(0, 3)) +\n  labs(title = \"Beispiele von Beta Verteilungen\",\n       y = expression(p(theta*\"|\"*a*\", \"*b))) +\n  theme(panel.grid = element_blank()) +\n  facet_grid(b~a)\n\n\n\n\nFigure 3: Beta Verteilungen\n\n\n\nDie uniforme Verteilung erhalten wir, wenn wir \\(\\alpha = \\beta = 1\\) setzen. Wenn wir \\(\\alpha = \\beta = 4\\) setzen, erhalten wir eine Verteilung mit Erwartungswert \\(0.5\\)—dies ist der Fall für alle Verteilungen in denen die beiden Parameter denselben Wert annehmen. Wenn wir ausdrücken wollen, dass wir A für die bessere Spielerin als B halten, dann wählen wir \\(\\alpha > \\beta\\).\n\nDie Verteilungsfunktionen heissen in R dbeta(), pbeta(), qbeta() und rbeta(). Die Parameter \\(\\alpha\\) und \\(\\beta\\) heissen ganz einfach shape1 und shape2.\n\n\n\nprior4 <- dbeta(x = p_grid, shape1 = 20, shape2 = 4)\ncompute_posterior(likelihood, prior4)\n\n\n\n\nWenn wir überzeugt wären, dass B besser ist, dann hätten wir vielleicht diesen Prior:\n\n\nprior5 <- dbeta(x = p_grid, shape1 = 4, shape2 = 20)\ncompute_posterior(likelihood, prior5)\n\n\n\n\nEinfluss des Priors auf den Posterior\nDie obigen Beispiele illustrieren, dass die Prior-Verteilung einen grossen Einfluss auf die Schätzung haben kann. Deshalb ist bei der Wahl der Prior Vorsichtig geboten; vor allem wenn es darum geht, Parameter in statistischen Modellen zu schätzen, wollen wir oft sogenannte non-informative Priors, welche keine nennenswerten Einfluss auf die Schätzung haben.\n\nProbieren Sie ein ähnliches Beispiel als interaktive Webapp: A First Lesson in Bayesian Inference\nSchätzmethoden\nDie Methode, welche wir oben angewandt haben, nennt sich “grid approximation.” Dies bezieht sich auf den Prior—wir haben einen Vektor von Priorwerten definiert, und jeden Punkt mit der Likelihood multipliziert, in direkter Anwendung von Bayes’ Theorem. Dies ist für dieses kleine Problem sehr gut möglich. Daneben gibt es für dieses Beispiel auch die analytische Lösung. Die Beta-Prior-Verteilung kann mit den beobachteten Erfolgen und Versuchen updated werden, um eine neue Beta-Verteilung mit den Parametern \\(k + \\alpha\\) und \\(n - k + \\beta\\).\n\nMehr dazu einem Blog Post.\nNun kommen diese beiden Ansatz für die meisten Datenanalyseprobleme nicht in Frage. Die analytische Lösung ist nicht möglich, und die grid-search Methode ist nicht in endlicher Zeit durchführbar. In diesem Fall sind wir auf approximative Methoden angewiesen. Eine Variante, welche die Posterior-Verteilung durch Ziehen von Zufallszahlen exploriert, heisst Markov CHain Monte Carlo. Davon gibt es wiederum verschiedene Varianten.\nStan\nEin Algorithmus, welcher als state-of-the-art gilt, heisst Hamiltonian Monte Carlo, und eine spezielle Variante davon heisst NUTS (No-U-Turn Sampler). Auf diese Inferenzmethode ist die probabilistische Programmiersprache Stan spezialisiert.\nWir werden in dieser Veranstaltung selten Stan direkt verwenden, da es mittlerweile gute R Packages gibt, mit denen die Bedienung von Stan sehr einfach geworden ist. Ich halte es jedoch für pädagogisch wertvoll, wenn wir uns zumindest dieses Beta-Binomial Besipiel in Stan anschauen.\nDie Vorgehensweise ist genauso, wie oben beschrieben: wir schreiben zuerst ein probabilistischen Model5 auf, und bedingen dann auf die beobachteten Daten.\nDas Modell wird in der Stan Sprache geschrieben. Wir verwenden hier einen Beta(4, 4) Prior.\n\ndata {\n  int<lower=0> n; // number of games\n  int<lower=0> k; // number of wins\n  \n}\n\nparameters {\n  real<lower=0, upper=1> theta;\n}\n\nmodel {\n  theta ~ beta(4, 4);\n  k ~ binomial(n, theta);\n}\n\nDieser Code wird in einem File mit dem Suffix .stan gespeichert.\n\nIch nenne das Stan File binomial-model.stan.\nWir laden das Package rstan, das R Interface zu Stan.\n\n\nlibrary(rstan)\n\n\n\nDann definieren wir die beobachteten Daten:\n\n\nstan_data <- list(\n  n = 9,\n  k = 6\n)\n\n\n\nUnd benutzen die Funktion stan(), um die Posterior-Verteilung zu sampeln.\n\n\nfit <- stan(file = \"binomial-model.stan\",  # Stan program\n            data = stan_data,    # named list of data\n            chains = 4,          # number of Markov chains\n            iter = 2000,         # total number of iterations per chain\n            cores = 4)           # number of cores (could use one per chain)\n\n\n\n\n\nprint(fit)\n\n\nInference for Stan model: binomial-model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff\ntheta   0.59    0.00 0.12   0.35   0.51   0.59   0.67   0.80  1518\nlp__  -12.03    0.02 0.71 -14.07 -12.22 -11.76 -11.57 -11.52  1451\n      Rhat\ntheta    1\nlp__     1\n\nSamples were drawn using NUTS(diag_e) at Tue Mar  9 06:14:17 2021.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\ntraceplot(fit)\n\n\n\n\n\n\nbayesplot::mcmc_intervals(fit, \"theta\")\n\n\n\n\n\n\nbayesplot::mcmc_areas(fit, \"theta\")\n\n\n\n\nbrms\n\n\nlibrary(brms)\n\n\n\n\n\ndata <- tibble(k = 6, n = 9)\n\n\n\n\n\npriors <- prior(beta(4, 4), class = b, lb = 0, ub = 1)\n\nm1 <- brm(k | trials(n) ~ 0 + Intercept, family = binomial(link = \"identity\"),\n          prior = priors,\n          data = data,\n          control = list(adapt_delta = 0.9),\n          file = \"models/binomial-2\")\n\n\n\n\n\nplot(m1)\n\n\n\n\nPosterior-Verteilungen zusammenfassen\nWir erhalten mit Bayesianischer Inferenz zwar Posterior-Verteilungen, aber oftmals wollen wir diese zusammen, damit wir eine Entscheidung fällen können.\nDies wird häufig anhand bestimmter Kennzahlen gemacht. Z.B. können wir den Mittelwert oder Median und eine Ober- und Untergrenze wählen. Ein solches Interval wird credible interval genannt. Häufig wird ein \\(95\\%\\) credible interval angegeben, aber es hindert uns nichts daran, ein \\(50\\%\\) oder \\(80\\%\\) credible interval zu benutzen. Mit der median_qi() vom Package tidybayes können wir das .width Argument benutzen:\n\n\nlibrary(tidybayes)\n\n\n\n\n\nm1 %>%\n  spread_draws(b_Intercept) %>% \n  median_qi(.width = c(.50, .80, .95)) %>% \n  kableExtra::kbl()\n\n\n\nb_Intercept\n\n\n.lower\n\n\n.upper\n\n\n.width\n\n\n.point\n\n\n.interval\n\n\n0.5885875\n\n\n0.5025237\n\n\n0.6682483\n\n\n0.50\n\n\nmedian\n\n\nqi\n\n\n0.5885875\n\n\n0.4231849\n\n\n0.7428155\n\n\n0.80\n\n\nmedian\n\n\nqi\n\n\n0.5885875\n\n\n0.3514341\n\n\n0.8102628\n\n\n0.95\n\n\nmedian\n\n\nqi\n\n\nMit mean_qi() erhalten wir Mittelwert und credible intervals.\nUm die Posterior-Verteilung zu visualisieren, können wir die Verteilung mit einem credible interval kombinieren.\n\n\nm1 %>%\n  spread_draws(b_Intercept) %>%\n  ggplot(aes(x = b_Intercept)) +\n  stat_halfeye(.width = c(.50, .80, .95))\n\n\n\n\n\nWas ist der Unterschied zwischen einem Konfidenzintervall und einem credible interval? Welches Intervall würden Sie verwenden, um eine Wahrscheinlichkeitsaussage über einen Parameter zu machen?\n\nWeiterführende Literatur\nEtz and Vandekerckhove (2018) bieten eine sehr gründliche Einführung, mit vielen (Harry Potter-themed) Beispielen. Schoot et al. (2014) ist ebenfalls eine sehr gründliche Einführung. Eine empfehlenswerte Übersicht über Literatur, vor allem in Bezug auf Psychologie, geben Etz et al. (2016).\nDas Buch von (Kruschke 2015) ist ein gutes Lehrbuch, obwohl der R Code nicht unbedingt sehr benutzerfreundlich ist.\nMein Favorit ist McElreath (2020).\n\n\n\nEtz, Alexander, Quentin Frederik Gronau, Fabian Dablander, Peter Edelsbrunner, and Beth Baribault. 2016. “How to Become a Bayesian in Eight Easy Steps: An Annotated Reading List,” August. https://doi.org/10.31234/osf.io/ph6sw.\n\n\nEtz, Alexander, and Joachim Vandekerckhove. 2018. “Introduction to Bayesian Inference for Psychology.” Psychonomic Bulletin & Review 25 (1): 5–34. https://doi.org/10.3758/s13423-017-1262-3.\n\n\nGigerenzer, Gerd. 2004. “Mindless Statistics.” The Journal of Socio-Economics 33 (5): 587–606. https://doi.org/10.1016/j.socec.2004.09.033.\n\n\n———. 2018. “Statistical Rituals: The Replication Delusion and How We Got There.” Advances in Methods and Practices in Psychological Science 1 (2): 198–218. https://doi.org/10.1177/2515245918771329.\n\n\nHoekstra, Rink, Richard D. Morey, Jeffrey N. Rouder, and Eric-Jan Wagenmakers. 2014. “Robust Misinterpretation of Confidence Intervals.” Psychonomic Bulletin & Review 21 (5): 1157–64. https://doi.org/10.3758/s13423-013-0572-3.\n\n\nKruschke, John. 2015. Doing Bayesian Data Analysis (Second Edition). Boston: Academic Press.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. A Chapman & Hall Book. CRC Press. https://books.google.ch/books?id=Ie2vxQEACAAJ.\n\n\nSchoot, Rens van de, David Kaplan, Jaap Denissen, Jens B. Asendorpf, Franz J. Neyer, and Marcel A. G. van Aken. 2014. “A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research.” Child Development 85 (3): 842–60. https://doi.org/10.1111/cdev.12169.\n\n\nWagenmakers, Eric-Jan. 2007. “A Practical Solution to the Pervasive Problems of p Values.” Psychonomic Bulletin & Review 14 (5): 779–804. https://doi.org/10.3758/BF03194105.\n\n\nWasserstein, Ronald L., and Nicole A. Lazar. 2016. “The ASA Statement on p-Values: Context, Process, and Purpose.” The American Statistician 70 (2): 129–33. https://doi.org/10.1080/00031305.2016.1154108.\n\n\nestimate1 und estimate2↩︎\nestimate↩︎\nstatistic↩︎\np.value↩︎\nDies nennt man ein generatives Modell↩︎\n",
      "last_modified": "2021-03-09T06:20:00+01:00"
    },
    {
      "path": "02-bayesian-stats.html",
      "title": "Bayesianische Statistik",
      "description": "Sampling, Modelle, Parameterschätzung.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\n\n\n",
      "last_modified": "2021-03-09T06:20:01+01:00"
    },
    {
      "path": "exercise-1.html",
      "title": "Übung 1",
      "description": "Schätzen des Parameters $\\theta$ einer Binomialverteilung.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nAufgabenstellung\nAufgaben\nAufgabe 1\nAufgabe 2\nAufgabe 3\nAufgabe 4\nAufgabe 5\nAufgabe 6\n\n\nAufgabenstellung\n\nSie haben für diese Übung eine Woche Zeit. Laden Sie Ihre Lösung als Rmarkdown File bis Donnerstag, 11. März um 00:00 Uhr, in den Order für Übung 1 auf ILIAS. Falls Rmarkdown nicht funkionieren sollte, werden auch Lösungen in Form eines R Skriptes akzeptiert. Nennen Sie Ihr File Matrikelnummer_Nachname_uebung-1.Rmd oder Matrikelnummer_Nachname_uebung-1.R, z. B. 15-172-874_Nachname_uebung-1.Rmd.\n\n\nBevor Sie einreichen, vergewissern Sie sich bitte, dass Ihr Rmarkdown File geknittet werden kann, und dass der R Code ohne Fehler läuft.\n\nSie verabreichen einen Test, der aus 10 Fragen besteht. Die Fragen sind etwa gleich schwierig, und Sie sind sich sicher, dass die Fragen weder zu leicht noch zu schwierig für Ihre Schüler sind. Beim Betrachten der Resultate fällt Ihnen das Ergebnis eines Schülers besonders auf.\nBisher hatten Sie 4 solcher Tests verabreicht. Dieser Schüler schneidet normalerweise unterdurchschnittlich ab, mit Ergebnissen von \\(4/10\\), \\(3/10\\), \\(2/10\\) und \\(4/10\\) richtigen Antworten. Sie haben sich schon vorgenommen, die Elter des Schülers zu kontaktieren, da Sie sich Sorgen machen.\n\n\ntibble(Test = as_factor(1:5), Resultate = c(4/10, 3/10, 2/10, 4/10, NA)) %>% \n  ggplot(aes(Test, Resultate, fill = Test)) +\n  geom_bar(stat = 'identity') +\n  scale_fill_viridis_d(end = 0.8) +\n  scale_y_continuous(limits = c(0, 1)) +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Bisherige Leistungen\")\n\n\n\n\nBei diesem Test sehen die Antworten aber so aus:\n\n\nanswers <- c(1, 1, 1, 1, 0, 1, 1, 1, 1, 1)\n\n\n\n1 bedeutet, die Frage wurde richtig beantwortet, 0 steht für eine inkorrekte Antwort.\nBerechnen Sie die Anzahl korrekter Antworten, sowie die Anzahl korrekter Antworten in den bisherigen Tests.\n\n\nncorrect <- sum(answers)\nnquestions <- length(answers)\nprior_ncorrect <- 4 + 3 + 2 +4\nprior_nquestions <- 4 * 10\nprior_nwrong <- prior_nquestions - prior_ncorrect\n\n\n\nSie freuen sich—vielleicht hat sich der Schüler bei diesem Test besonders Mühe gegeben. Sie überlegen sich, ob Sie nun warten sollen, oder doch mit den Eltern einen Termin für ein Gespräch abmachen sollen.\nVielleicht kann Ihnen Bayesianische Inferenz helfen?\nAufgaben\nVersuchen Sie, mit Hilfe Ihres Vorwissens über die Leistungen des Schülers seine Fähigkeit (ability), Fragen richtig zu beantworten, zu schätzen. Da Sie wissen, dass Sie die Fähigkeit nur ungenau schätzen können, wollen Sie Ihre Unsicherheit mit einer Posterior Distribution quantifizieren.\n\nDer R Code, den Sie bei dieser Übung brauchen, ist schon gegeben. Sie brauchen lediglich die Lücken auszufüllen.\nZum Beispiel:\n\nncorrect <- sum(___)\n\nwird zu\n\n\nncorrect <- sum(answers)\n\n\n\n\nDefinieren sie zuerst einen Vektor, der alle möglichen Werte des Parameters \\(\\theta\\) enthält.\n\n\nn_points <- 100\ntheta_grid <- seq(from = 0 , to = 1 , length.out = n_points)\n\n\n\nAufgabe 1\nBerechnen Sie nun die Wahrscheinlichkeit, das Testergebnis des Schülers zu erreichen, d.h. die Wahrscheinlichkeit der Daten für jeden möglichen Parameterwert.\n\nlikelihood <- dbinom(x = ___ , size = ___ , prob = theta_grid)\n\nSie können diese Wahrscheinlichkeit so graphisch darstellen.\n\n\ntibble(theta_grid, likelihood) %>% \n  ggplot(aes(x = theta_grid, y = likelihood)) +\n  geom_line()\n\n\n\nAufgabe 2\nWenn Sie kein Vorwissen über die bisherigen Testresultate des Schülers hätten: Was würden Sie als Schätzung der Fähigkeit des Schülers benutzen?\n\nSie haben nur das aktuelle Resultat zur Verfügung (9 richtige Antowrten in 10 Fragen).\nAufgabe 3\nVersuchen Sie nun, Ihr Vorwissen über die Leistungen des Schülers in Form einer Prior-Verteilung auszudrücken.\n\nVersuchen Sie es mit einer Beta-Verteilung. Schauen Sie im Skript nach.\n\nprior <- dbeta(x = theta_grid, shape1 = ___,  shape2 = ___)\n\nAufgabe 4\nBerechnen Sie die Posterior-Verteilung als Produkt von Likelihood und Ihrem Prior.\n\n\nunstandardized_posterior <- likelihood * prior\n\nposterior <- unstandardized_posterior / sum(unstandardized_posterior)\n\nposterior\n\n\n\nAufgabe 5\nStellen Sie Prior, Likelihood und Posterior grafisch dar\n\n\ndf <- tibble(theta_grid, prior, likelihood, posterior)\n\ndf %>%\n  pivot_longer(-theta_grid, names_to = \"distribution\", values_to = \"density\") %>% \n  mutate(distribution = as_factor(distribution)) %>% \n  ggplot(aes(theta_grid, density, color = distribution)) +\n  geom_line(size = 1.5) +\n  geom_vline(xintercept = 9/10, linetype = \"dashed\") +\n  scale_color_viridis_d(end = 0.8) +\n  xlab(\"Theta Werte\") +\n  ylab(\"\") +\n  facet_wrap(~distribution, scales = \"free_y\") +\n  theme_bw()\n\n\n\nAufgabe 6\nWas ist die Warscheinlichkeit, dass jemand mit solchen Vorleistungen mindestens 9 Fragen von 10 beantwortet, falls die Vorleistungen tatsächlich die wahre Fähigkeiten der Schüler messen?\n\n\n\n",
      "last_modified": "2021-03-09T06:20:04+01:00"
    },
    {
      "path": "index.html",
      "title": "Methodenkurs Neurowissenschaft im Computerlab: FS 2021 ",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-03-09T06:20:05+01:00"
    },
    {
      "path": "leistungskontrolle.html",
      "title": "Leistungskontrollen",
      "description": "Es gibt __6__ Übungen geben, von denen __5__ bestanden werden müssen.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLeistungskontrolle\n\nLeistungskontrolle\n\nLeistungskontrollen werden in Form von Übungen erbracht. Es wird 6 Übungen geben, von denen 5 bestanden werden müssen.\nEs gibt die Möglichkeit, Übungen falls nötig (nach Verbesserung) ein zweites Mal einzureichen.\nÜbungen werden in einem entsprechenden Ordner auf ILIAS hochgeladen, und zwar in Form eines R Scripts, oder, noch besser, als Rmarkdown File.\n\nEin gute Einführung in Rmarkdown finden Sie z.B. hier.\nFalls Datenfiles dazugehören, sollte alles in einem ZIP File komprimiert werden. Sowohl das R Script als auch das RMarkdown File sollten self-contained sein, d.h. es ist möglich, den Code unabhängig vom Rechner, auf dem der Code geschrieben wurde, auszuführen. Deswegen ist es empfehlenswert, die Übungen als RStudio Projekt hochzuladen.\n\nEine Einführung in RStudio finden Sie hier.\n\n\n\n",
      "last_modified": "2021-03-09T06:20:06+01:00"
    },
    {
      "path": "rmarkdown.html",
      "title": "Rmarkdown",
      "description": "Arbeiten mit RStudio Projects und Rmarkdown.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n RStudio Projekte\nRmarkdown\n\n RStudio Projekte\nIch empfehle (wie schon in den Statistik Übungen) immer in einem RStudio Projekt zu arbeiten. Als Faustregel: jedes Datenanalyseprojekt kriegt ein eigenes RStudio Projekt. Die Vorteile sind:\nMan kann das Projekt schliessen und wieder im gleichen Zustand öffnen, d.h. alle offenen Files werden wieder hergestellt. So kann man z.B. eine Woche lang nicht an einem Projekt arbeiten, und danach wieder in dem Zustand weiterfahren, in dem man aufgehört hat.\nMan muss keine absoluten Pfade benutzen, sondern nur relative.\nRmarkdown\n\nRmarkdown ist eine Erweiterung der Markdown Sprache, welche wiederum eine einfache Sprache ist, um Text zu formattieren.\n\nMit Markdown ist es möglich, HTML oder LaTeX zu erstellen, ohne das man selber viel HTML/LaTeX kennen muss. LaTeX ist vor allem dann gut, wenn man viele Formeln benutzt, oder komplizierte Dokumente erstellt.\n\nRmarkdown erlaubt zusätzlich die Einbindung von R Code; dieser wird zuerst evaluiert, und der Ouput wird zu Markdown konvertiert. Damit lassen sich Paper und Bachelor/Masterarbeiten schreiben, was sehr sinnvoll ist, wenn man mit R arbeitet.\nEin weiterer Grund, Rmarkdown zu benutzen, ist Reproduzierbarkeit. Man kann Code für Datenanalyse direkt in ein Manuskript einbinden, so dass die Resultate immer up-to-date sind, und nicht zwischen Dokumenten hin-und her kopiert werden müssen (was sehr fehleranfällig ist).\nEin exzellente Einführung in Rmarkdown finden Sie im Blog von Danielle Navarro: Einführung in Rmarkdown.\n\nSchauen Sie sich die Slides an.\n\n\nDieses Skript wird mit Rmarkdown erstellt. Wenn Sie auf das Icon oben rechts klicken, sehen Sie den Source Code.\nRStudio macht es sehr einfach, mit Rmarkdown zu arbeiten. Un ein neues Dokument zu erstellen, öffnen Sie das File Menu. Dort wählen Sie New File aus, und dann Rmarkdown....\nSie sehen dann dieses Dialogfenster:\n\n\n\nHier können Sie das Output Format bestimmen: HTML, PDF (LaTeX), oder Word.\nNachdem Sie OK geklickt haben, erhalten Sie ein Rmarkdown Template. Dies können Sie mit der Knit Funktion zu einem HTML (oder PDF, Word) konvertieren. Zuerst müssen Sie das Dokument jedoch speichern.\n\nErstellen Sie ein Rmarkdown Dokument und speichern Sie es. Probieren Sie verschiedene Output Formate, und knitten Sie das Dokument.\n\nIn der nächsten Übung machen wir zwei ganz wichtige Dinge: wir benutzen Rmarkdown, und wir generieren Daten. Genauer gesagt benutzen wir ein statistisches (probabilistisches) Modell, um Zufallszahlen zu generieren. In dieser Übung generieren wir Daten, die dem statistischen Modell eines t-Tests entsprechen.\n\nFügen Sie folgenden R Code in einen oder (noch besser) mehreren Code Chunks ein. Benützen Sie Markdown Text, um das Ganze zu kommentieren., d.h. die Kommentare zwischen den R Code Zeilen könnten auch als Prosa zwischen R Code Chunks stehen.\n\n\n\nlibrary(tidyverse)\n\nset.seed(12)\n\n# Number of people wearing fancy hats\nN_fancyhats <- 50 \n\n# Number of people not wearing fancy hats\nN_nofancyhats <- 50\n\n# Population mean of creativity for people wearing fancy hats\nmu_fancyhats <- 103 \n\n# Population mean of creativity for people wearing no fancy hats\nmu_nofancyhats <- 98 \n\n# Average population standard deviation of both groups\nsigma <- 15 \n\n# Generate data\nfancyhats = tibble(Creativity = rnorm(N_fancyhats, mu_fancyhats, sigma),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(N_nofancyhats, mu_nofancyhats, sigma),\n                 Group = \"No Fancy Hat\")\n\n\nFancyHat <- bind_rows(fancyhats, nofancyhats)  %>%\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\n\n# plot both groups\nFancyHat %>% \n    ggplot() +\n    geom_boxplot ((aes(y = Creativity, x = Group))) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nMit diesem Code simulieren Sie zwei experimentelle Gruppen, mit je 50 Teilnehmern. Die eine Gruppe trug “fancy hats”, die andere Gruppe nicht. Wir generieren normalverteilte Zufallszahlen—für die Fancy Hat Gruppe mit \\(\\mu=103\\), für die No Fancy Hat mit \\(\\mu=98\\). Mit bind_rows() fügen wir beide Dataframes zusammen, und am Schluss machen wir einen Boxplot.\nWenn Sie eine R Code Chunk einfügen, z.B. mit Code > Insert Chunk, erhalten Sie ein Options Icon am oberen rechten Rand des Chunks. Hier können Sie wählen, ob der Code/Output angezeigt wird.\n\nFühren Sie einen (gerichteten) t-Test in einem Code Chunk durch. Zur Erinnerung: Sie brauchen die Funktion t.test() mit den Argumenten alternative = \"less\" und var.equal = TRUE.\n\nLösung\n\n\n    Two Sample t-test\n\ndata:  Creativity by Group\nt = -0.63685, df = 98, p-value = 0.2629\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 2.647764\nsample estimates:\nmean in group No Fancy Hat    mean in group Fancy Hat \n                  99.20888                  100.85606 \n\nÜbung\nDas gleiche Modell können Sie (für den ungerichteten Fall) auch als Allgemeines Lineares Modell formulieren.\n\n\n\nLösung\n\n\nCall:\nlm(formula = Creativity ~ Group, data = FancyHat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.448  -8.578  -1.704   8.645  33.224 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      99.209      1.829  54.245   <2e-16 ***\nGroupFancy Hat    1.647      2.586   0.637    0.526    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.93 on 98 degrees of freedom\nMultiple R-squared:  0.004121,  Adjusted R-squared:  -0.006041 \nF-statistic: 0.4056 on 1 and 98 DF,  p-value: 0.5257\n\n\n\n\nLösung\n\n\n\n\n\n\n\n# A tibble: 1 x 3\n  `No Fancy Hat` `Fancy Hat`  diff\n           <dbl>       <dbl> <dbl>\n1           99.2        101. -1.65\n\n\n\n\n",
      "last_modified": "2021-03-09T06:20:07+01:00"
    },
    {
      "path": "uebersicht.html",
      "title": "Übersicht",
      "description": "Inhalt des Kurses und Software.\n",
      "author": [
        {
          "name": {},
          "url": "https://github.com/awellis"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nEinleitung\nInhalt dieses Kurses\nSoftware\n\n\nEinleitung\nInhalt dieses Kurses\n\nIn diesem Kurs beschäftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nIn diesem Kurs geht es um den behavioralen/kognitiven Teil dieses Forschungsgebiets—das bedeutet, mathematische Modelle, anhand derer experimentelle Daten analysiert werden können. Es gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Kapitel daraus verwenden. Das Buch ist auf SpringerLink verfügbar: An Introduction to Model-Based Cognitive Neuroscience. Ausserdem werden wir Beispiele aus dem Buch von Farrell and Lewandowsky (2015) benutzten. Dieses Buch ist leider nicht frei erhältlich—es gibt jedoch eine Website mit Code und Übungen: Computational Modeling of Cognition and Behavior. Wir werden uns ab Mitte des Semesters mit Modellen von Entscheidungsverhalten und kognitiven Modellen beschäftigen, darunter sogennante Bayesian Models of cognition. Damit ist gemeint, dass wir Bayesianische Inferenz als rationales Verhalten betrachten, und Abweichungen davon in menschlichem Verhalten zu suchen.\nWilson and Collins (2019) geben eine sehr gute Einführung in die Prinzipen der Modellierung, obschon das Paper nicht ganz so “simple” ist, wie der Titel verspricht.\nBevor wir zu den kognitiven Modellen kommen, werden wir uns im ersten Teil des Kurses mit Bayesianischer Inferenz beschäftigen, und mit Bayesianischer Datenanalyse. Dies ist nicht mit Bayesianischen Models of Cognition zu verwechslen—Bayesianische Models of Cognition sind Modelle vmenschlichen Verhaltens, oder der Funktionsweise von Gehirnen, während Bayesianische (oder auch frequentistische) Datenanalyse dazu benutzt wird, die Parameter solcher Modelle zu schätzen.\nBayesianische Datenanalyse bietet gegenüber der frequentistischen Statistik viele Vorteile, erfordert aber auch ein Umdenken. Wir werden lernen, wie wir statistische Modelle als lineare Modelle formulieren können, entweder als allgemeine lineare Modelle (ALM), oder verallgemeinerte lineare Modelle (generalized linear models, GLM). Als nächtes folgen dann Multilevel Modelle, mit denen wir häufig verwendete Daten, wie binäre Antworten, oder Reaktionszeiten untersuchen können.\nDie Themen sind also:\nEinführung in die Bayesianische Datenanalyse\nBayesianische Multilevel Modelle\nMathematische Modelle von Entscheidungsverhalten\nModelle von kognitiven Prozessen (Bayesianische und andere)\nSoftware\n\nWir werden in diesem Kurs vor allem mit R arbeiten, aber wenn es um Bayesianische Datenanalyse geht, verwenden wir Stan. Dies ist eine probabilistische Programmiersprache, mit der man Monte Carlo Sampling in einfachen bis sehr komplexen Modellen durchführen kann.\nGlücklicherweise gibt es ein R Package, mit dem man von R aus Stan benutzen kann: RStan. Noch viel einfacher wird es, wenn wir brms oder rstanarm verwenden. Mit diesen Packages lassen sich Bayesianische statistische Modelle mit (fast) derselben Syntax wie frequentistische Modelle schätzen.\n\n\n\nFarrell, Simon, and Stephan Lewandowsky. 2015. “An Introduction to Cognitive Modeling.” In An Introduction to Model-Based Cognitive Neuroscience, edited by Birte U. Forstmann and Eric-Jan Wagenmakers, 3–24. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4939-2236-9_1.\n\n\nForstmann, Birte U., and Eric-Jan Wagenmakers. 2015. “Model-Based Cognitive Neuroscience: A Conceptual Introduction.” In An Introduction to Model-Based Cognitive Neuroscience, edited by Birte U. Forstmann and Eric-Jan Wagenmakers, 139–56. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4939-2236-9_7.\n\n\nWilson, Robert C, and Anne GE Collins. 2019. “Ten Simple Rules for the Computational Modeling of Behavioral Data.” Edited by Timothy E Behrens. eLife 8 (November): e49547. https://doi.org/10.7554/eLife.49547.\n\n\n\n\n",
      "last_modified": "2021-03-09T06:20:09+01:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
