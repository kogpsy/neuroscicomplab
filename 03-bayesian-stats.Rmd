---
title: "Bayesianische Statistik"
description: | 
  Lineare Modelle mit `brms`.
date: "`r Sys.Date()`"
author:
  - first_name: "Andrew"
    last_name: "Ellis"
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern 
    affiliation_url: https://www.kog.psy.unibe.ch
    orcid_id: 0000-0002-2788-936X

citation_url: https://kogpsy.github.io/neuroscicomplab/01-intro-bayesian-stats.html
# slug: ellis2021overview
bibliography: bibliography.bib
output: 
    distill::distill_article:
      toc: true
      toc_float: true
      toc_depth: 2
      code_folding: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```


# Mittelwert und Standardabweichung einer Normalverteilung schätzen


Wir haben 3 Datenpunkte mit den Werten $ y_1 = 85$ , $y_2 = 100$, und $y_3 = 115$. Wenn wir annehmen, dass diese Datenpunkte aus einer Normalverteilung kommen

$$ p(y | \mu, \sigma) = \frac{1}{Z} exp \left(- \frac{1}{2} \frac{(y-\mu)^2}{\sigma^2}\right)  $$ 
$Z = \sigma \sqrt{2\pi}$ ist eine Normalisierungskonstante. 


Wir können so die Wahrscheinlichkeit eines Datenpunktes berechnen, wenn wir wissen, was wir für $\mu$ und $\sigma$ einsetzen wollen. Unter der Annahme, dass die drei Datenpunkte unabhängig sind, ist die Wahrscheinlichkeit der Daten das Produkt der Einzelwahrscheinlichkeit.

Wie aber finden wir die beiden Parameter der Normalverteilung, $\mu$ und $\sigma$?


```{r normal-graphical-model, echo = FALSE, out.width = "20%", fig.cap="Graphical Model für normalverteilte Daten."}
knitr::include_graphics("images/normal-graphical-model-2.png")
```


```{r message=FALSE, warning=FALSE, results='hide'}
library(tidyverse)
```



```{r}
sequence_length <- 100

d1 <- crossing(y = seq(from = 50, to = 150, length.out = sequence_length),
              mu = c(87.8, 100, 112),
              sigma = c(7.35, 12.2, 18.4)) %>%
    mutate(density = dnorm(y, mean = mu, sd = sigma),
           mu = factor(mu, labels = str_c("mu==", c(87.8, 100, 112))),
           sigma = factor(sigma, 
                          labels = str_c("sigma==", c(7.35, 12.2, 18.4))))
```

```{r}
library(rmarkdown)

d1 %>% 
  paged_table(options = list(rows.print = 6))
```



```{r eval=FALSE, include=FALSE}
theme_set(
  theme_bw() +
    theme(text = element_text(color = "white"),
          axis.text = element_text(color = "black"),
          axis.ticks = element_line(color = "white"),
          legend.background = element_blank(),
          legend.box.background = element_rect(fill = "white",
                                               color = "transparent"),
          legend.key = element_rect(fill = "white",
                                    color = "transparent"),
          legend.text = element_text(color = "black"),
          legend.title = element_text(color = "black"),
          panel.background = element_rect(fill = "white",
                                          color = "white"),
          panel.grid = element_blank()))
```

```{r}
d1 %>% 
  ggplot(aes(x = y)) +
  geom_ribbon(aes(ymin = 0, ymax = density),
              fill = "steelblue") +
  geom_vline(xintercept = c(85, 100, 115), 
             linetype = 3, color = "white") +
  geom_point(data = tibble(y = c(85, 100, 115)),
             aes(y = 0.002),
             size = 2, color = "red") +
  scale_y_continuous(expression(italic(p)(italic(y)*"|"*mu*", "*sigma)), 
                     expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  ggtitle("Welche Normalverteilung?") +
  coord_cartesian(xlim = c(60, 140)) +
  facet_grid(sigma ~ mu, labeller = label_parsed) +
  theme_bw() +
  theme(panel.grid = element_blank())
```



## t-Test als Lineares Modell

Wir nehmen als Beispiel folgenden (fiktiven) Datensatz [@kruschkeDoingBayesianData2015]. WIr haben IQ Scores einer Stichprobe, welche eine "Smart Drug" konsumiert hat. Wir wissen, dass IQ so normiert sind, dass wir in der Bevölkerung einen Mittelwert von 100, und eine Standardabweichung von 15 haben. Nun wollen wir wissen, ob und wie sich die "Smart Drug" Gruppe von von diesem erwarteten Mittelwert unterscheidet. Gleichzeitig haben wir auch eine Gruppe, welche ein Placebo konsumiert hat. 





Die Daten sind aus @kruschkeDoingBayesianData2015; wir können hier einfach die Daten von Hand eingeben, und zu einem Dataframe zusammenfügen:

```{r}
smart = tibble(IQ = c(101,100,102,104,102,97,105,105,98,101,100,123,105,103,
                      100,95,102,106,109,102,82,102,100,102,102,101,102,102,
                      103,103,97,97,103,101,97,104,96,103,124,101,101,100,
                      101,101,104,100,101),
               Group = "SmartDrug")

placebo = tibble(IQ = c(99,101,100,101,102,100,97,101,104,101,102,102,100,105,
                        88,101,100,104,100,100,100,101,102,103,97,101,101,100,101,
                        99,101,100,100,101,100,99,101,100,102,99,100,99),
                 Group = "Placebo")

TwoGroupIQ <- bind_rows(smart, placebo) %>%
    mutate(Group = fct_relevel(as.factor(Group), "Placebo"))
```

<aside>
Wenn wir einen Unterschied zwischen den beiden Gruppen testen wollen, können wir hier eine t- oder Welch-Test machen.
</aside>

```{r message=FALSE, warning=FALSE}
library(kableExtra)
```

```{r}
TwoGroupIQ %>%
  group_by(Group) %>%
  summarise(mean = mean(IQ),
            sd = sd(IQ)) %>%
  mutate(across(where(is.numeric), round, 2)) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```


```{r}
d <- TwoGroupIQ %>% 
  filter(Group == "SmartDrug") %>% 
  mutate(Group = fct_drop(Group))
```


```{r smart-drug}
d %>% 
  ggplot(aes(x = IQ)) +
  geom_histogram(fill = "skyblue3", binwidth = 1) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)))
```




```{r message=FALSE, warning=FALSE}
library(brms)
```





```{r}
priors <- get_prior(IQ ~ 1,
          data = d)
priors
```



```{r}
library(tidybayes)
priors_df <- priors %>% 
    parse_dist(prior)

priors_df %>% 
    ggplot(aes(y = class, dist = .dist, args = .args)) +
    stat_dist_halfeye() +
    facet_wrap(~class, scales = "free_x")


priors_df %>% 
    mutate(class = case_when(coef == "" ~ class,
                             coef == "Intercept" ~ "Intercept"))

priors_df %>%  
    ggplot(aes(y = class, dist = .dist, args = .args)) + 
    stat_dist_halfeyeh() +
    labs(title = "Prior distributions",
         x = NULL)
```

```{r}
tibble(x = seq(from = 0, to = 10, by = .025)) %>% 
  mutate(d = dt(x, df = 3)) %>% 
  ggplot(aes(x = x, ymin = 0, ymax = d)) +
  geom_ribbon(fill = "skyblue3") +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  coord_cartesian(xlim = c(0, 8),
                  ylim = c(0, 0.35)) +
  xlab(expression(sigma)) +
  labs(subtitle = "Half-student-t Distribution: Prior für Standardabweichung.") +
  theme_bw(base_size = 14)
```


```{r}
tibble(x = seq(from = 0, to = 200, by = .025)) %>% 
  mutate(d = dnorm(x, mean = 102, sd = 3)) %>% 
  ggplot(aes(x = x, ymin = 0, ymax = d)) +
  geom_ribbon(fill = "skyblue3") +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = NULL) +
  coord_cartesian(xlim = c(50, 150),
                  ylim = c(0, 0.15)) +
  xlab(expression(sigma)) +
  labs(subtitle = "Normalverteilter Prior für Mittelwert") +
  theme_bw(base_size = 14)
```





```{r}
m1_prior <- brm(IQ ~ 1,
          prior = priors,
          data = d,
          sample_prior = "only",
          file = "models/twogroupiq-prior-1")
```





```{r}
plot(m1_prior)
```




```{r}
prior_pred_1 <- d %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m1_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = d) +
  scale_color_brewer() +
  theme_tidybayes()
```


```{r}
prior_pred_1
```

```{r}
m1 <- brm(IQ ~ 1,
          prior = priors,
          data = d,
          file = "models/twogroupiq-1")
```




```{r}
plot(m1)
```


```{r}
print(m1)
```


```{r}
library(patchwork)
mcmc_plot(m1, pars = "b") / mcmc_plot(m1, pars = "sigma")
```


```{r}
samples <- posterior_samples(m1) %>% 
  transmute(mu = b_Intercept, sigma = sigma)
```



```{r}
library(tidybayes)

samples %>% 
  select(mu) %>% 
  median_qi(.width = c(.50, .80, .95, .99)) %>% 
  ggplot(aes(x = mu, xmin = .lower, xmax = .upper)) +
  geom_pointinterval() +
  ylab("") +
  theme_tidybayes()
```
```{r}
samples %>% 
  select(mu) %>% 
  ggplot(aes(x = mu)) +
  stat_halfeye() +
  theme_tidybayes()
```

```{r}
samples %>% 
  select(sigma) %>% 
  ggplot(aes(x = sigma)) +
  stat_halfeye(point_interval = mode_hdi) +
  theme_tidybayes()
```





```{r}
post_pred_1 <- d %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m1) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = d) +
  scale_color_brewer() +
  theme_tidybayes()
```


```{r}
post_pred_1
```



```{r}
cowplot::plot_grid(prior_pred_1, 
                   post_pred_1, 
                   labels = c('Prior predictive', 'Posterior predictive'), 
                   label_size = 12,
                   align = "h",
                   nrow = 2)
```





## Zwei Gruppen

```{r echo = FALSE}
library(ggridges)
library(patchwork)

TwoGroupIQ %>%
   ggplot(aes(x = IQ, fill = Group)) +
      geom_dotplot(binwidth = 1) + facet_wrap(~Group) +
      scale_fill_manual(values = c("#0288b7", "#a90010"), guide = FALSE) +
      # scale_x_continuous(breaks = seq(1, 10, 1)) +
      scale_y_continuous(breaks = NULL) +
      labs(y = "Count", x = "IQ") +
      facet_wrap(~ Group, nrow = 2) +
      theme(panel.grid.major.x = element_blank())

p_iq_ridges <- TwoGroupIQ %>%
   ggplot(aes(x = IQ, y = fct_rev(Group), fill = Group)) +
     stat_density_ridges(quantile_lines = TRUE,
                       quantiles = 2,
                       scale = 3, color = "white") +
      scale_fill_manual(values = c("#0288b7", "#a90010"), guide = FALSE) +
      scale_x_continuous(breaks = seq(0, 10, 2)) +
      labs(x = "IQ", y = NULL,
         subtitle = "White line shows median rating")



p_iq_ridges +
  plot_annotation(title = "IQ difference",
                  subtitle = "Smart drug vs placebo",
                  theme = theme(plot.title = element_text(face = "bold",
                                                          size = rel(1.5))))
```





## t-Test as general linear model

Assuming equal variances, we can write

$$ Y = \alpha + \beta X + \epsilon$$
$$ \epsilon \sim N(0, \sigma^2) $$

where $X$ is indicates group membership.

```{r echo=TRUE, message=FALSE, warning=FALSE}
levels(TwoGroupIQ$Group)
```






Using R's formula notation, we can write this as

```{r echo=TRUE}
fit_ols <- lm(IQ ~ Group,
              data = TwoGroupIQ)
```

<aside>
The outcome `IQ` is modeled as a function of `Group`)
</aside>


More formally:

$$ IQ = Placebo + \beta \cdot SmartDrug  + \epsilon$$

$$ \epsilon \sim N(0, \sigma^2) $$


The $\beta$ parameter therefore represents the difference between groups.

```{r echo=TRUE}
 summary(fit_ols)
```


```{r}
contrasts(TwoGroupIQ$Group)
```

```{r}
mm1 <- model.matrix(~ Group, data = TwoGroupIQ)
head(mm1)
```

```{r}
as_tibble(mm1) %>% 
  group_by(GroupSmartDrug) %>% 
  slice_sample(n= 3)
```
```{r}
mm2 <- model.matrix(~ 0 + Group, data = TwoGroupIQ)
as_tibble(mm2) %>% 
  group_by(GroupSmartDrug) %>% 
  slice_sample(n= 3)
```







```{r normal-graphical-model-2, echo = FALSE, out.width = "20%", fig.cap="Graphical Model für 2 Gruppen."}
knitr::include_graphics("images/two-group-iq-graphical-model.png")
```



```{r}
priors2 <- get_prior(IQ ~ 1 + Group,
                     data = TwoGroupIQ)
```

```{r}
priors2
```


```{r}
priors3 <- get_prior(IQ ~ 0 + Group,
                     data = TwoGroupIQ)
```

```{r}
priors3
```






```{r}
priors2_b <- prior(normal(0, 2), class = b)
```



```{r}
m2_prior <- brm(IQ ~ 1 + Group,
          prior = priors2_b,
          data = TwoGroupIQ,
          sample_prior = "only",
          file = "models/twogroupiq-prior-2")
```



```{r}
prior_pred_2 <- TwoGroupIQ %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m2_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = TwoGroupIQ) +
  scale_color_brewer() +
  theme_tidybayes()

prior_pred_2
```

```{r}
priors3_b <- prior(normal(100, 10), class = b)
```

```{r}
m3_prior <- brm(IQ ~ 0 + Group,
          prior = priors3_b,
          data = TwoGroupIQ,
          sample_prior = "only",
          file = "models/twogroupiq-prior-3")
```



```{r}
prior_pred_3 <- TwoGroupIQ %>%
  modelr::data_grid(Group) %>%
  add_predicted_draws(m3_prior) %>%
  ggplot(aes(y = Group, x = .prediction)) +
  stat_interval(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = IQ), alpha = 0.4,  data = TwoGroupIQ) +
  scale_color_brewer() +
  theme_tidybayes()

prior_pred_3
```


```{r}
m2 <- brm(IQ ~ 1 + Group,
          prior = priors2_b,
          data = TwoGroupIQ,
          file = "models/twogroupiq-2")
```


```{r}
m3 <- brm(IQ ~ 0 + Group,
          prior = priors3_b,
          data = TwoGroupIQ,
          file = "models/twogroupiq-3")
```


```{r}
summary(m2)
```

```{r}
summary(m3)
```


```{r}
mcmc_plot(m2, "b_GroupSmartDrug")
```

```{r}
mcmc_plot(m3, "b")
```
```{r}
samples_m3 <- posterior_samples(m3) %>% 
    transmute(Placebo = b_GroupPlacebo, 
              SmartDrug = b_GroupSmartDrug,
              sigma = sigma)
```


```{r}
samples_m3 <- samples_m3 %>% 
  mutate(diff = SmartDrug - Placebo,
         effect_size = diff/sigma)
```





```{r}
samples_m3 %>% 
  select(diff) %>% 
  median_qi()
```

```{r}
samples_m3 %>% 
  select(diff) %>% 
  ggplot(aes(x = diff)) +
  stat_halfeye(point_interval = median_qi) +
  theme_tidybayes()
```

```{r}
samples_m3 %>% 
  select(effect_size) %>% 
  ggplot(aes(x = effect_size)) +
  stat_halfeye(point_interval = median_qi) +
  theme_tidybayes()
```



```{r}
fit_eqvar <- brm(IQ ~ Group,
                 data = TwoGroupIQ,
                 file = here::here("models/fit_eqvar"))
```

```{r}
fit_eqvar %>%
    gather_draws(b_GroupSmartDrug) %>%
    ggplot(aes(y = .variable, x = .value)) +
    stat_halfeye(fill = "Steelblue4") +
    geom_vline(xintercept = 0, color = "white", linetype = 1, size = 1) +
    ylab("") +
    xlab("Estimated difference") +
    theme_tidybayes()
```

```{r}
grid <- TwoGroupIQ %>%
    modelr::data_grid(Group)

fits_IQ <- grid %>%
    add_fitted_draws(fit_eqvar)

preds_IQ <- grid %>%
    add_predicted_draws(fit_eqvar)

pp_eqvar <- TwoGroupIQ %>%
    ggplot(aes(x = IQ, y = Group)) +
    stat_halfeye(aes(x = .value),
                  scale = 0.7,
                  position = position_nudge(y = 0.1),
                  data = fits_IQ,
                  .width = c(.66, .95, 0.99)) +
    stat_interval(aes(x = .prediction),
                   data = preds_IQ,
                   .width = c(.66, .95, 0.99)) +
    scale_x_continuous(limits = c(75, 125)) +
    geom_point(data = TwoGroupIQ) +
    scale_color_brewer() +
	labs(title = "Equal variance model predictions") +
  theme_tidybayes()

pp_eqvar
```


