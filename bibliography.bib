
@incollection{alexanderReciprocalInteractionsComputational2015,
  title = {Reciprocal {{Interactions}} of {{Computational Modeling}} and {{Empirical Investigation}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Alexander, William H. and Brown, Joshua W.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {321--338},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_16},
  abstract = {Models in general, and computational neural models in particular, are useful to the extent they fulfill three aims, which roughly constitute a life cycle of a model. First, at birth, models must account for existing phenomena, and with mechanisms that are no more complicated than necessary. Second, at maturity, models must make strong, falsifiable predictions that can guide future experiments. Third, all models are by definition incomplete, simplified representations of the mechanisms in question, so they should provide a basis of inspiration to guide the next generation of model development, as new data challenge and force the field to move beyond the existing models. Thus the final part of the model life cycle is a dialectic of model properties and empirical challenge. In this phase, new experimental data test and refine the model, leading either to a revised model or perhaps the birth of a new model. In what follows, we provide an outline of how this life cycle has played out in a particular series of models of the dorsal anterior cingulate cortex (ACC).},
  file = {/Users/andrew/Dropbox/Zotero/Alexander_Brown2015/Alexander and Brown - 2015 - Reciprocal Interactions of Computational Modeling .pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Anterior cingulate cortex,Cognitive control,Computational neural model,Dialectic,Error likelihood,Performance monitoring,Reinforcement learning},
  langid = {english}
}

@incollection{ashbyIntroductionFMRI2015,
  title = {An {{Introduction}} to {{fMRI}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Ashby, F. Gregory},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {91--112},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_5},
  abstract = {Functional magnetic resonance imaging (fMRI) provides an opportunity to indirectly observe neural activity noninvasively in the human brain as it changes in near real time. Most fMRI experiments measure the blood oxygen-level dependent (BOLD) signal, which rises to a peak several seconds after a brain area becomes active. Several experimental designs are common in fMRI research. Block designs alternate periods in which subjects perform some task with periods of rest, whereas event-related designs present the subject with a set of discrete trials. After the fMRI experiment is complete, pre-processing analyses prepare the data for task-related analyses. The most popular task-related analysis uses the General Linear Model to correlate a predicted BOLD response with the observed activity in each brain region. Regions where this correlation is high are identified as task related. Connectivity analysis then tries to identify active regions that belong to the same functional network. In contrast, multivariate methods, such as independent component analysis and multi-voxel pattern analysis identify networks of event-related regions, rather than single regions, so they simultaneously address questions of functional connectivity.},
  file = {/Users/andrew/Dropbox/Zotero/Ashby2015/Ashby - 2015 - An Introduction to fMRI.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {BOLD response,fMRI,Functional connectivity analysis,General Linear Model,Hemodynamic response function,Multiple comparisons problem,Preprocessing},
  langid = {english}
}

@incollection{bogaczOptimalDecisionMaking2015,
  title = {Optimal {{Decision Making}} in the {{Cortico}}-{{Basal}}-{{Ganglia Circuit}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Bogacz, Rafal},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {291--302},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_14},
  abstract = {This chapter presents a model assuming that during decision making the cortico-basal-ganglia circuit computes probabilities that considered alternatives are correct, according to Bayes' theorem. The model suggests how the equation of Bayes' theorem is mapped onto the functional anatomy of a circuit involving the cortex, basal ganglia and thalamus. The chapter also describes the relationship of the model to other models of decision making and experimental data.},
  file = {/Users/andrew/Dropbox/Zotero/Bogacz2015/Bogacz - 2015 - Optimal Decision Making in the Cortico-Basal-Gangl.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Action selection,Basal ganglia,Decision making},
  langid = {english}
}

@incollection{borstUsingACTRCognitive2015,
  title = {Using the {{ACT}}-{{R Cognitive Architecture}} in {{Combination With fMRI Data}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Borst, Jelmer P. and Anderson, John R.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {339--352},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_17},
  abstract = {In this chapter we discuss how the ACT-R cognitive architecture can be used in combination with fMRI data. ACT-R is a cognitive architecture that can provide a description of the processes from perception through to action for a wide range of cognitive tasks. It has a computational implementation that can be used to create models of specific tasks, which yield exact predictions in the form of response times and accuracy measures. In the last decade, researchers have extended the predictive capabilities of ACT-R to fMRI data. Since ACT-R provides a model of all the components in task performance it can address brain-wide activation patterns. fMRI data can now be used to inform and constrain the architecture, and, on the other hand, the architecture can be used to interpret fMRI data in a principled manner. In the following sections we first introduce cognitive architectures, and ACT-R in particular. Then, on the basis of an example dataset, we explain how ACT-R can be used to create fMRI predictions. In the third and fourth section of this chapter we discuss two ways in which these predictions can be used: region-of-interest and model-based fMRI analysis, and how the results can be used to inform the architecture and to interpret fMRI data.},
  file = {/Users/andrew/Dropbox/Zotero/Borst_Anderson2015/Borst and Anderson - 2015 - Using the ACT-R Cognitive Architecture in Combinat.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {ACT-R,Cognitive Architecture,fMRI,Model-based fMRI,ROI analysis},
  langid = {english}
}

@incollection{ditterichDistinguishingModelsPerceptual2015,
  title = {Distinguishing {{Between Models}} of {{Perceptual Decision Making}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Ditterich, Jochen},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {277--290},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_13},
  abstract = {Mathematical models are a useful tool for gaining insight into mechanisms of decision making. However, like other scientific methods, its application is not without pitfalls. This chapter demonstrates that it can be difficult to distinguish between alternative models and it illustrates that a model-based approach benefits from the availability of a rich dataset that provides sufficient constraints. Ideally, the dataset is not only comprised of behavioral data, but also contains neural data that provide information about the internal processing. The chapter focuses on two examples taken from perceptual decision making. In one case, information about response time distributions is used to reject a model that is otherwise consistent with accuracy data and mean response times. In the other case, only the availability of neural data allows a distinction between two alternative models that are both consistent with the behavioral data.},
  file = {/Users/andrew/Dropbox/Zotero/Ditterich2015/Ditterich - 2015 - Distinguishing Between Models of Perceptual Decisi.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Choice,Feedback inhibition,Feedforward inhibition,Parietal cortex,Perceptual decision making,Response time,Stochastic integration,Time-variant},
  langid = {english}
}

@article{doornBayesFactorsMixed2021a,
  title = {Bayes {{Factors}} for {{Mixed Models}}},
  author = {family=Doorn, given=Johnny, prefix=van, useprefix=false and Aust, Frederik and Haaf, Julia M. and Stefan, Angelika and Wagenmakers, Eric-Jan},
  date = {2021-02-22T12:02:03},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/y65h8},
  abstract = {Although Bayesian mixed models are increasingly popular for data analysis in psychology and other fields, there remains considerable ambiguity on the most appropriate Bayes factor hypothesis test to quantify the degree to which the data support the presence or absence of an experimental effect. Specifically, different choices for both the null model and the alternative model are possible, and each choice constitutes a different definition of an effect resulting in a different test outcome. We outline the common approaches and focus on the impact of aggregation, the effect of measurement error, the choice of prior distribution, and the detection of interactions. For concreteness, three example scenarios showcase how seemingly innocuous choices can lead to dramatic differences in statistical evidence. We hope this work will facilitate a more explicit discussion about best practices in Bayes factor hypothesis testing in mixed models.},
  file = {/Users/andrew/Dropbox/Zotero/Doorn et al/2021/Doorn et al. - 2021 - Bayes Factors for Mixed Models2.pdf},
  keywords = {Bayes factors,Mixed effects,Mixed models,Quantitative Methods,Random effects,Social and Behavioral Sciences,Statistical Methods}
}

@incollection{farrellIntroductionCognitiveModeling2015,
  title = {An {{Introduction}} to {{Cognitive Modeling}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Farrell, Simon and Lewandowsky, Stephan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {3--24},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_1},
  abstract = {We provide a tutorial on the basic attributes of computational cognitive models\textemdash models that are formulated as a set of mathematical equations or as a computer simulation. We first show how models can generate complex behavior and novel insights from very simple underlying assumptions about human cognition. We survey the different classes of models, from description to explanation, and present examples of each class. We then illustrate the reasons why computational models are preferable to purely verbal means of theorizing. For example, we show that computational models help theoreticians overcome the limitations of human cognition, thereby enabling us to create coherent and plausible accounts of how we think or remember and guard against subtle theoretical errors. Models can also measure latent constructs and link them to individual differences, which would escape detection if only the raw data were considered. We conclude by reviewing some open challenges.},
  file = {/Users/andrew/Dropbox/Zotero/Farrell_Lewandowsky2015/Farrell and Lewandowsky - 2015 - An Introduction to Cognitive Modeling.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Agent-based modelling,Computational models,Model comparison,Necessity,Parameter interpretation,Practice,Scientific reasoning},
  langid = {english}
}

@incollection{forstmannIntroductionHumanBrain2015,
  title = {An {{Introduction}} to {{Human Brain Anatomy}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Forstmann, Birte U. and Keuken, Max C. and Alkemade, Anneke},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {71--89},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_4},
  abstract = {This tutorial chapter provides an overview of the human brain anatomy. Knowledge of brain anatomy is fundamental to our understanding of cognitive processes in health and disease; moreover, anatomical constraints are vital for neurocomputational models and can be important for psychological theorizing as well. The main challenge in understanding brain anatomy is to integrate the different levels of description ranging from molecules to macroscopic brain networks. This chapter contains three main sections. The first section provides a brief introduction to the neuroanatomical nomenclature. The second section provides an introduction to the different levels of brain anatomy and describes commonly used atlases for the visualization of functional imaging data. The third section provides a concrete example of how human brain structure relates to performance.},
  file = {/Users/andrew/Dropbox/Zotero/Forstmann et al2015/Forstmann et al. - 2015 - An Introduction to Human Brain Anatomy.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Connectional neuroanatomy,functional MRI,Neuroanatomical atlases,Sectional neuroanatomy,Structural MRI,Structure-function relationships,Ultra high resolution MRI},
  langid = {english}
}

@incollection{forstmannModelBasedCognitiveNeuroscience2015,
  title = {Model-{{Based Cognitive Neuroscience}}: {{A Conceptual Introduction}}},
  shorttitle = {Model-{{Based Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {139--156},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_7},
  abstract = {This tutorial chapter shows how the separate fields of mathematical psychology and cognitive neuroscience can interact to their mutual benefit. Historically, the field of mathematical psychology is mostly concerned with formal theories of behavior, whereas cognitive neuroscience is mostly concerned with empirical measurements of brain activity. Despite these superficial differences in method, the ultimate goal of both disciplines is the same: to understand the workings of human cognition. In recognition of this common purpose, mathematical psychologists have recently started to apply their models in cognitive neuroscience, and cognitive neuroscientists have borrowed and extended key ideas that originated from mathematical psychology. This chapter consists of three main sections: the first describes the field of mathematical psychology, the second describes the field of cognitive neuroscience, and the third describes their recent combination: model-based cognitive neuroscience.},
  file = {/Users/andrew/Dropbox/Zotero/Forstmann_Wagenmakers2015/Forstmann and Wagenmakers - 2015 - Model-Based Cognitive Neuroscience A Conceptual I.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Blood Oxygenation Level Dependent,Blood Oxygenation Level Dependent Signal,Cognitive Neuroscience,Drift Rate,Mathematical Psychology},
  langid = {english}
}

@incollection{frankLinkingLevelsComputation2015,
  title = {Linking {{Across Levels}} of {{Computation}} in {{Model}}-{{Based Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Frank, Michael J.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {159--177},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_8},
  abstract = {Computational approaches to cognitive neuroscience encompass multiple levels of analysis, from detailed biophysical models of neural activity to abstract algorithmic or normative models of cognition, with several levels in between. Despite often strong opinions on the `right' level of modeling, there is no single panacea: attempts to link biological with higher level cognitive processes require a multitude of approaches. Here I argue that these disparate approaches should not be viewed as competitive, nor should they be accessible to only other researchers already endorsing the particular level of modeling. Rather, insights gained from one level of modeling should inform modeling endeavors at the level above and below it. One way to achieve this synergism is to link levels of modeling by quantitatively fitting the behavioral outputs of detailed mechanistic models with higher level descriptions. If the fits are reasonable (e.g., similar to those achieved when applying high level models to human behavior), one can then derive plausible links between mechanism and computation. Model-based cognitive neuroscience approaches can then be employed to manipulate or measure neural function motivated by the candidate mechanisms, and to test whether these are related to high level model parameters. I describe several examples of this approach in the domain of reward-based learning, cognitive control, and decision making and show how neural and algorithmic models have each informed or refined the other.},
  file = {/Users/andrew/Dropbox/Zotero/Frank2015/Frank - 2015 - Linking Across Levels of Computation in Model-Base.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Algorithms,Basal ganglia,Computational models,Decision making,Dopamine,Neural networks,Prefrontal cortex,Reinforcement learning},
  langid = {english}
}

@article{guestHowComputationalModeling2021,
  title = {How {{Computational Modeling Can Force Theory Building}} in {{Psychological Science}}},
  author = {Guest, Olivia and Martin, Andrea E.},
  date = {2021-01-22},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  pages = {1745691620970585},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620970585},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined\textemdash what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
  file = {/Users/andrew/Zotero/storage/SVPEKCYE/Guest and Martin - 2021 - How Computational Modeling Can Force Theory Buildi.pdf},
  keywords = {computational model,open science,scientific inference,theoretical psychology},
  langid = {english}
}

@incollection{heathcoteIntroductionGoodPractices2015,
  title = {An {{Introduction}} to {{Good Practices}} in {{Cognitive Modeling}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Heathcote, Andrew and Brown, Scott D. and Wagenmakers, Eric-Jan},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {25--48},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_2},
  abstract = {Cognitive modeling can provide important insights into the underlying causes of behavior, but the validity of those insights rests on careful model development and checking. We provide guidelines on five important aspects of the practice of cognitive modeling: parameter recovery, testing selective influence of experimental manipulations on model parameters, quantifying uncertainty in parameter estimates, testing and displaying model fit, and selecting among different model parameterizations and types of models. Each aspect is illustrated with examples.},
  file = {/Users/andrew/Dropbox/Zotero/Heathcote et al2015/Heathcote et al. - 2015 - An Introduction to Good Practices in Cognitive Mod.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Cognition,Model,Model selection,Parameter estimation,Quantitative,Simulation study,Theory},
  langid = {english}
}

@incollection{kokPredictiveCodingSensory2015,
  title = {Predictive {{Coding}} in {{Sensory Cortex}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Kok, Peter and family=Lange, given=Floris P., prefix=de, useprefix=true},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {221--244},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_11},
  abstract = {In recent years, predictive coding has become an increasingly influential model of how the brain processes sensory information. Predictive coding theories state that the brain is constantly trying to predict the inputs it receives, and each region in the cortical sensory hierarchy represents both these predictions and the mismatch between predictions and input (prediction error). In this chapter, we review the extant empirical evidence for this theory, as well as discuss recent theoretical advances. We find that predictive coding provides a good explanation for many phenomena observed in perception, and generates testable hypotheses. Furthermore, we suggest possible avenues for further empirical testing and for broadening the perspective of the role predictive coding may play in cognition.},
  file = {/Users/andrew/Dropbox/Zotero/Kok_de Lange2015/Kok and de Lange - 2015 - Predictive Coding in Sensory Cortex.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Expectation,fMRI,Perception,Perceptual inference,Prediction,Predictive coding},
  langid = {english}
}

@incollection{loganInhibitoryControlMind2015,
  title = {Inhibitory {{Control}} in {{Mind}} and {{Brain}}: {{The Mathematics}} and {{Neurophysiology}} of the {{Underlying Computation}}},
  shorttitle = {Inhibitory {{Control}} in {{Mind}} and {{Brain}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Logan, Gordon D. and Schall, Jeffrey D. and Palmeri, Thomas J.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {303--320},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_15},
  abstract = {We develop desiderata for a computational theory of response inhibition that links mathematical psychology with neuroscience. The theory must be explicit mathematically and computationally, and grounded in behavior and neurophysiology. The theory must provide quantitative accounts of complexities of behavior in response inhibition tasks and must predict the neural activity that underlies performance. We evaluate three current theories of response inhibition in the stop signal paradigm using these desiderata, and we find that one theory fulfills the desiderata better than the others.},
  file = {/Users/andrew/Dropbox/Zotero/Logan et al2015/Logan et al. - 2015 - Inhibitory Control in Mind and Brain The Mathemat.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Computational theory of response inhibition,Mathematical psychology,Neuroscience,Response inhibition},
  langid = {english}
}

@article{navarroIfMathematicalPsychology2020,
  title = {If Mathematical Psychology Did Not Exist We Might Need to Invent It: {{A}} Comment on Theory Building in Psychology},
  shorttitle = {If Mathematical Psychology Did Not Exist We Might Need to Invent It},
  author = {Navarro, Danielle},
  date = {2020-03-16T20:56:43},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/ygbjp},
  abstract = {It is commonplace, when discussing the subject of psychological theory, to write articles from the assumption that psychology differs from physical sciences in that we have no theories that would support cumulative, incremental science. In this brief paper I discuss one counterexample, namely Shepard's (1987) law of generalization and the various Bayesian extensions that it inspired over the last three decades. Using Shepard's law as a running example I argue that psychological theory building is not a statistical problem; mathematical formalism is theoretically beneficial; measurement and theory have a complex relationship; rewriting old theory can yield new insights; and finally, that theoretical growth can drive empirical work. Though generally suggesting that the tools of mathematical psychology are valuable to the psychological theorist, the paper also comments on some limitations to this approach.},
  file = {/Users/andrew/Zotero/storage/VP6P5EU5/Navarro - 2020 - If mathematical psychology did not exist we might .pdf},
  keywords = {Cognitive Psychology,Concepts and Categories,Meta-science,Reasoning,Social and Behavioral Sciences,Theory and Philosophy of Science}
}

@incollection{oreillyBayesianModelsCognitive2015,
  title = {Bayesian {{Models}} in {{Cognitive Neuroscience}}: {{A Tutorial}}},
  shorttitle = {Bayesian {{Models}} in {{Cognitive Neuroscience}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {O'Reilly, Jill X. and Mars, Rogier B.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {179--197},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_9},
  abstract = {This chapter provides an introduction to Bayesian models and their application in cognitive neuroscience. The central feature of Bayesian models, as opposed to other classes of models, is that Bayesian models represent the beliefs of an observer as probability distributions, allowing them to integrate information while taking its uncertainty into account. In the chapter, we will consider how the probabilistic nature of Bayesian models makes them particularly useful in cognitive neuroscience. We will consider two types of tasks in which we believe a Bayesian approach is useful: optimal integration of evidence from different sources, and the development of beliefs about the environment given limited information (such as during learning). We will develop some detailed examples of Bayesian models to give the reader a taste of how the models are constructed and what insights they may be able to offer about participants' behavior and brain activity.},
  file = {/Users/andrew/Dropbox/Zotero/O’Reilly_Mars2015/O’Reilly and Mars - 2015 - Bayesian Models in Cognitive Neuroscience A Tutor.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Attention,Bayes,Bayesian modelling,Probability,Uncertainty},
  langid = {english}
}

@article{rousseletFewSimpleSteps2016,
  title = {A Few Simple Steps to Improve the Description of Group Results in Neuroscience},
  author = {Rousselet, Guillaume A. and Foxe, John J. and Bolam, J. Paul},
  date = {2016},
  journaltitle = {European Journal of Neuroscience},
  volume = {44},
  pages = {2647--2651},
  issn = {1460-9568},
  doi = {10.1111/ejn.13400},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.13400},
  file = {/Users/andrew/Dropbox/Zotero/Rousselet et al/2016/Rousselet et al. - 2016 - A few simple steps to improve the description of g.pdf;/Users/andrew/Zotero/storage/HFQZRAIL/ejn.html},
  langid = {english},
  number = {9}
}

@report{rousseletReactionTimesOther2019,
  title = {Reaction Times and Other Skewed Distributions: Problems with the Mean and the Median},
  shorttitle = {Reaction Times and Other Skewed Distributions},
  author = {Rousselet, Guillaume and Wilcox, Rand R.},
  date = {2019-01-17T11:18:00},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/3y54r},
  abstract = {To summarise skewed (asymmetric) distributions, such as reaction times, typically the mean or the median are used as measures of central tendency. Using the mean might seem surprising, given that it provides a poor measure of central tendency for skewed distributions, whereas the median provides a better indication of the location of the bulk of the observations. However, the sample median is biased: with small sample sizes, it tends to overestimate the population median. This is not the case for the mean. Based on this observation, Miller (1988) concluded that ''sample medians must not be used to compare reaction times across experimental conditions when there are unequal numbers of trials in the conditions.'' Here we replicate and extend Miller (1988), and demonstrate that his conclusion was ill-advised for several reasons. First, the median's bias can be corrected using a percentile bootstrap bias correction. Second, a careful examination of the sampling distributions reveals that the sample median is median unbiased, whereas the mean is median biased when dealing with skewed distributions. That is, on average the sample mean estimates the population mean, but typically this is not the case. In addition, simulations of false and true positives in various situations show that no method dominates. Crucially, neither the mean nor the median are sufficient or even necessary to compare skewed distributions. Different questions require different methods and it would be unwise to use the mean or the median in all situations. Better tools are available to get a deeper understanding of how distributions differ: we illustrate the hierarchical shift function, a powerful alternative that relies on quantile estimation. All the code and data to reproduce the figures and analyses in the article are available online.},
  file = {/Users/andrew/Dropbox/Zotero/Rousselet_Wilcox/2019/Rousselet and Wilcox - 2019 - Reaction times and other skewed distributions pro.pdf},
  keywords = {bias,bootstrap,estimation,mean,median,Meta-science,quantile,Quantitative Methods,sampling,skewness,Social and Behavioral Sciences,Statistical Methods,trimmed mean}
}

@incollection{singmannIntroductionMixedModels2019,
  title = {An {{Introduction}} to {{Mixed Models}} for {{Experimental Psychology}}},
  booktitle = {New {{Methods}} in {{Cognitive Psychology}}},
  author = {Singmann, Henrik and Kellen, David},
  editor = {Spieler, Daniel and Schumacher, Eric},
  date = {2019-10-28},
  edition = {1},
  pages = {4--31},
  publisher = {{Routledge}},
  doi = {10.4324/9780429318405-2},
  file = {/Users/andrew/Zotero/storage/SBC6A7LI/Singmann and Kellen - 2019 - An Introduction to Mixed Models for Experimental P.pdf},
  isbn = {978-0-429-31840-5},
  langid = {english}
}

@incollection{smithIntroductionDiffusionModel2015,
  title = {An {{Introduction}} to the {{Diffusion Model}} of {{Decision Making}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Smith, Philip L. and Ratcliff, Roger},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {49--70},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_3},
  abstract = {The diffusion model assumes that two-choice decisions are made by accumulating successive samples of noisy evidence to a response criterion. The model has a pair of criteria that represent the amounts of evidence needed to make each response. The time taken to reach criterion determines the decision time and the criterion that is reached first determines the response. The model predicts choice probabilities and the distributions of response times for correct responses and errors as a function of experimental conditions such as stimulus discriminability, speed-accuracy instructions, and manipulations of relative stimulus frequency, which affect response bias. This chapter describes the main features of the model, including mathematical methods for obtaining response time predictions, methods for fitting it to experimental data, including alternative fitting criteria, and ways to represent the fit to multiple experimental conditions graphically in a compact way. The chapter concludes with a discussion of recent work in psychology that links evidence accumulation to processes of perception, attention, and memory, and in neuroscience, to neural firing rates in the oculomotor control system in monkeys performing saccade-to-target decision tasks.},
  file = {/Users/andrew/Dropbox/Zotero/Smith_Ratcliff2015/Smith and Ratcliff - 2015 - An Introduction to the Diffusion Model of Decision.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Choice probability,Decision-making,Diffusion process,Random walk,Response time},
  langid = {english}
}

@article{speckmanDeltaPlotsCoherent2008a,
  title = {Delta {{Plots}} and {{Coherent Distribution Ordering}}},
  author = {Speckman, Paul L and Rouder, Jeffrey N and Morey, Richard D and Pratte, Michael S},
  date = {2008-08},
  journaltitle = {The American Statistician},
  volume = {62},
  pages = {262--266},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313008X333493},
  file = {/Users/andrew/Dropbox/Zotero/Speckman et al/2008/Speckman et al. - 2008 - Delta Plots and Coherent Distribution Ordering2.pdf},
  langid = {english},
  number = {3}
}

@incollection{spragueUsingHumanNeuroimaging2015,
  title = {Using {{Human Neuroimaging}} to {{Examine Top}}-down {{Modulation}} of {{Visual Perception}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Sprague, Thomas C. and Serences, John T.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {245--274},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_12},
  abstract = {Both univariate and multivariate analysis methods largely have focused on characterizing how measurements from neural firing rates, EEG electrodes, or fMRI voxels change as a function of stimulus parameters or task demands \textendash they focus on characterizing changes in neural signals. However, in cognitive neuroscience we are often interested in how these changes in neural signals collectively modify representations of information. We compare methods whereby activation patterns across entire brain regions can be used to reconstruct representations of information to more traditional univariate and multivariate analysis approaches. We highlight findings using these methods, focusing on how a representation-based analysis approach yields novel insights into how information is encoded, maintained and manipulated under various task demands.},
  file = {/Users/andrew/Dropbox/Zotero/Sprague_Serences2015/Sprague and Serences - 2015 - Using Human Neuroimaging to Examine Top-down Modul.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Analysis,Attention,Decoding,EEG,Encoding,fMRI,Neuroimaging,Reconstruction,Vision,Working memory},
  langid = {english}
}

@incollection{stuphornIntroductionNeuroscientificMethods2015,
  title = {An {{Introduction}} to {{Neuroscientific Methods}}: {{Single}}-Cell {{Recordings}}},
  shorttitle = {An {{Introduction}} to {{Neuroscientific Methods}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Stuphorn, Veit and Chen, Xiaomo},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {113--137},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_6},
  abstract = {This chapter describes the role of single-cell recordings in understanding the mechanisms underlying human cognition. Cognition is a function of the brain, a complex computational network, whose most elementary nodes are made up out of individual neurons. These neurons encode information and influence each other through a dynamically changing pattern of action potentials. For this reason, the activity of neurons in the awake, behaving brain constitutes the most fundamental form of neural data for cognitive neuroscience. This chapter discusses a number of technical issues and challenges of single-cell neurophysiology using a recent project of the authors as an example. We discuss issues such as the choice of an appropriate animal model, the role of psychophysics, technical challenges surrounding the simultaneous recording of multiple neurons, and various methods for perturbation experiments. The chapter closes with a consideration of the challenge that the brain's complexity poses for fully understanding any realistic nervous circuit, and of the importance of conceptual insights and mathematical models in the interpretation of single-cell recordings.},
  file = {/Users/andrew/Dropbox/Zotero/Stuphorn_Chen2015/Stuphorn and Chen - 2015 - An Introduction to Neuroscientific Methods Single.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Action potentials,Animal models,Behavior,Decision making,Electrophysiological recording,Frontal cortex,Nervous circuit,Perturbation experiment,Primate},
  langid = {english}
}

@incollection{turnerConstrainingCognitiveAbstractions2015,
  title = {Constraining {{Cognitive Abstractions Through Bayesian Modeling}}},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  author = {Turner, Brandon M.},
  editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  date = {2015},
  pages = {199--220},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-2236-9_10},
  abstract = {There are many ways to combine neural and behavioral measures to study cognition. Some ways are theoretical, and other ways are statistical. The predominant statistical approach treats both sources of data as independent and the relationship between the two measures is inferred by way of a (post hoc) regression analysis. In this chapter, we review an alternative approach that allows for flexible modeling of both measures simultaneously. We then explore and elaborate on several of the most important benefits of this modeling approach, and close with a model comparison of the Linear Ballistic Accumulator model and a drift diffusion model on neural and behavioral data.},
  file = {/Users/andrew/Dropbox/Zotero/Turner2015/Turner - 2015 - Constraining Cognitive Abstractions Through Bayesi.pdf},
  isbn = {978-1-4939-2236-9},
  keywords = {Bayesian,cognitive modeling,hierarchical,joint modeling framework},
  langid = {english}
}

@article{vanrooijFormalizingVerbalTheories2020,
  title = {Formalizing {{Verbal Theories}}},
  author = {family=Rooij, given=Iris, prefix=van, useprefix=true and Blokpoel, Mark},
  date = {2020-09-01},
  journaltitle = {Social Psychology},
  volume = {51},
  pages = {285--298},
  publisher = {{Hogrefe Publishing}},
  issn = {1864-9335},
  doi = {10.1027/1864-9335/a000428},
  abstract = {. We present a tutorial for formalizing verbal theories of psychological phenomena           \textendash{} social or otherwise. The approach builds on concepts and tools from the mathematics of computation.           We use intuitive examples and illustrate the intrinsic dialectical nature of the formalization process by           presenting dialogues between two fictive characters, called Verbal and             Formal. These characters' conversations and thought experiments serve to highlight           important lessons in theoretical modeling.},
  file = {/Users/andrew/Dropbox/Zotero/van Rooij_Blokpoel/2020/van Rooij and Blokpoel - 2020 - Formalizing Verbal Theories.pdf;/Users/andrew/Zotero/storage/E4QD293I/a000428.html;/Users/andrew/Zotero/storage/KYFYRFCK/a000428.html},
  number = {5}
}

@article{vossDiffusionModelsExperimental2013,
  title = {Diffusion {{Models}} in {{Experimental Psychology}}: {{A Practical Introduction}}},
  shorttitle = {Diffusion {{Models}} in {{Experimental Psychology}}},
  author = {Voss, Andreas and Nagler, Markus and Lerche, Veronika},
  date = {2013-01-01},
  journaltitle = {Experimental Psychology},
  volume = {60},
  pages = {385--402},
  issn = {1618-3169, 2190-5142},
  doi = {10.1027/1618-3169/a000218},
  abstract = {Stochastic diffusion models (Ratcliff, 1978) can be used to analyze response time data from binary decision tasks. They provide detailed information about cognitive processes underlying the performance in such tasks. Most importantly, different parameters are estimated from the response time distributions of correct responses and errors that map (1) the speed of information uptake, (2) the amount of information used to make a decision, (3) possible decision biases, and (4) the duration of nondecisional processes. Although this kind of model can be applied to many experimental paradigms and provides much more insight than the analysis of mean response times can, it is still rarely used in cognitive psychology. In the present paper, we provide comprehensive information on the theory of the diffusion model, as well as on practical issues that have to be considered for implementing the model.},
  file = {/Users/andrew/Dropbox/Zotero/Voss et al/2013/Voss et al. - 2013 - Diffusion Models in Experimental Psychology A Pra.pdf},
  langid = {english},
  number = {6}
}

@article{wagenmakersPracticalSolutionPervasive2007,
  title = {A Practical Solution to the Pervasive Problems of p Values},
  author = {Wagenmakers, Eric-Jan},
  date = {2007-10},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {14},
  pages = {779--804},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03194105},
  file = {/Users/andrew/Dropbox/Zotero/Wagenmakers/2007/Wagenmakers - 2007 - A practical solution to the pervasive problems ofp.pdf},
  langid = {english},
  number = {5}
}

@article{wilsonTenSimpleRules2019,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  date = {2019-11-26},
  journaltitle = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  file = {/Users/andrew/Dropbox/Zotero/Wilson_Collins/2019/Wilson and Collins - 2019 - Ten simple rules for the computational modeling of.pdf},
  keywords = {computational modeling,model fitting,reproducibility,validation}
}

@article{wilsonTenSimpleRules2019a,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  date = {2019-11-26},
  journaltitle = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  file = {/Users/andrew/Dropbox/Zotero/Wilson_Collins/2019/Wilson and Collins - 2019 - Ten simple rules for the computational modeling of2.pdf},
  keywords = {computational modeling,model fitting,reproducibility,validation}
}


